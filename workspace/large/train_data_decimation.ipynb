{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f38e88c4-a180-44c0-930c-ee618a009a93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da1be5a8-6fc1-4824-8ef5-dfb35660f8e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-08 17:07:46,579] Note: NumExpr detected 32 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "[2024-01-08 17:07:46,582] NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pppc\n",
    "from pppc.configs import PtychoNNTrainingConfigDict\n",
    "from pppc.ptychonn.trainer import PtychoNNTrainer\n",
    "from pppc.ptychonn.dataset_handle import HDF5Dataset\n",
    "from pppc.ptychonn.model import PtychoNNModel, PtychoNNTransposedConvModel\n",
    "from pppc.helper import transform_data_for_ptychonn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc996cd4-d304-4afd-b85a-dc0230c31638",
   "metadata": {},
   "source": [
    "Define some data transform functions for handling raw training data with different sizes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "663610f3-99d2-45b3-b0c2-976c131613ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Raw DP size 512, label 128; crop DPs to 384, then rescale to 128. (use default function in HDF5Dataset)\n",
    "transform_func_512_128 = None\n",
    "transform_func_kwargs_512_128 = None\n",
    "\n",
    "# Raw DP size 512, label 128; crop DPs to 256, then pad to 384, and rescale to 128. (use default function in HDF5Dataset)\n",
    "def transform_func_512_128_pad(dp):\n",
    "    dp = transform_data_for_ptychonn(dp, target_shape=(256, 256), discard_len=(128, 128))\n",
    "    dp = transform_data_for_ptychonn(dp, target_shape=(128, 128), discard_len=(-64, -64))\n",
    "    return dp\n",
    "transform_func_kwargs_512_128_pad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c0c711-4d0a-4924-a515-c9c3fc8904be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-08 17:07:48,138] Decimating dataset to 0.9 of the original size...\n",
      "[2024-01-08 17:07:48,362] Using DataParallel with 2 devices.\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:47<00:00,  1.19s/it]\n",
      "[2024-01-08 17:12:40,024] Saving improved model after Val Loss improved from inf to 0.58586\n",
      "[2024-01-08 17:12:40,097] Epoch: 0 | FT  | Train Loss: 0.67709 | Val Loss: 0.58586\n",
      "[2024-01-08 17:12:40,097] Epoch: 0 | Amp | Train Loss: 0.1036 | Val Loss: 0.0220\n",
      "[2024-01-08 17:12:40,098] Epoch: 0 | Ph  | Train Loss: 0.574 | Val Loss: 0.564\n",
      "[2024-01-08 17:12:40,099] Epoch: 0 | Ending LR: 0.000050 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:44<00:00,  1.18s/it]\n",
      "[2024-01-08 17:17:27,356] Saving improved model after Val Loss improved from 0.58586 to 0.54447\n",
      "[2024-01-08 17:17:27,412] Epoch: 1 | FT  | Train Loss: 0.58031 | Val Loss: 0.54447\n",
      "[2024-01-08 17:17:27,413] Epoch: 1 | Amp | Train Loss: 0.0224 | Val Loss: 0.0200\n",
      "[2024-01-08 17:17:27,414] Epoch: 1 | Ph  | Train Loss: 0.558 | Val Loss: 0.524\n",
      "[2024-01-08 17:17:27,415] Epoch: 1 | Ending LR: 0.000081 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:41<00:00,  1.17s/it]\n",
      "[2024-01-08 17:22:10,938] Saving improved model after Val Loss improved from 0.54447 to 0.38386\n",
      "[2024-01-08 17:22:11,065] Epoch: 2 | FT  | Train Loss: 0.46140 | Val Loss: 0.38386\n",
      "[2024-01-08 17:22:11,067] Epoch: 2 | Amp | Train Loss: 0.0225 | Val Loss: 0.0200\n",
      "[2024-01-08 17:22:11,068] Epoch: 2 | Ph  | Train Loss: 0.439 | Val Loss: 0.364\n",
      "[2024-01-08 17:22:11,069] Epoch: 2 | Ending LR: 0.000111 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:34<00:00,  1.14s/it]\n",
      "[2024-01-08 17:26:48,016] Saving improved model after Val Loss improved from 0.38386 to 0.31628\n",
      "[2024-01-08 17:26:48,095] Epoch: 3 | FT  | Train Loss: 0.35199 | Val Loss: 0.31628\n",
      "[2024-01-08 17:26:48,096] Epoch: 3 | Amp | Train Loss: 0.0213 | Val Loss: 0.0193\n",
      "[2024-01-08 17:26:48,096] Epoch: 3 | Ph  | Train Loss: 0.331 | Val Loss: 0.297\n",
      "[2024-01-08 17:26:48,096] Epoch: 3 | Ending LR: 0.000141 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:35<00:00,  1.14s/it]\n",
      "[2024-01-08 17:31:26,381] Saving improved model after Val Loss improved from 0.31628 to 0.29890\n",
      "[2024-01-08 17:31:26,485] Epoch: 4 | FT  | Train Loss: 0.30142 | Val Loss: 0.29890\n",
      "[2024-01-08 17:31:26,486] Epoch: 4 | Amp | Train Loss: 0.0211 | Val Loss: 0.0245\n",
      "[2024-01-08 17:31:26,487] Epoch: 4 | Ph  | Train Loss: 0.280 | Val Loss: 0.274\n",
      "[2024-01-08 17:31:26,487] Epoch: 4 | Ending LR: 0.000171 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:45<00:00,  1.18s/it]\n",
      "[2024-01-08 17:36:14,358] Saving improved model after Val Loss improved from 0.29890 to 0.25902\n",
      "[2024-01-08 17:36:14,459] Epoch: 5 | FT  | Train Loss: 0.27382 | Val Loss: 0.25902\n",
      "[2024-01-08 17:36:14,460] Epoch: 5 | Amp | Train Loss: 0.0209 | Val Loss: 0.0190\n",
      "[2024-01-08 17:36:14,461] Epoch: 5 | Ph  | Train Loss: 0.253 | Val Loss: 0.240\n",
      "[2024-01-08 17:36:14,461] Epoch: 5 | Ending LR: 0.000198 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:39<00:00,  1.16s/it]\n",
      "[2024-01-08 17:40:56,069] Saving improved model after Val Loss improved from 0.25902 to 0.24808\n",
      "[2024-01-08 17:40:56,167] Epoch: 6 | FT  | Train Loss: 0.25304 | Val Loss: 0.24808\n",
      "[2024-01-08 17:40:56,168] Epoch: 6 | Amp | Train Loss: 0.0202 | Val Loss: 0.0199\n",
      "[2024-01-08 17:40:56,168] Epoch: 6 | Ph  | Train Loss: 0.233 | Val Loss: 0.228\n",
      "[2024-01-08 17:40:56,169] Epoch: 6 | Ending LR: 0.000168 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:36<00:00,  1.15s/it]\n",
      "[2024-01-08 17:45:34,855] Saving improved model after Val Loss improved from 0.24808 to 0.23812\n",
      "[2024-01-08 17:45:34,933] Epoch: 7 | FT  | Train Loss: 0.23996 | Val Loss: 0.23812\n",
      "[2024-01-08 17:45:34,935] Epoch: 7 | Amp | Train Loss: 0.0199 | Val Loss: 0.0190\n",
      "[2024-01-08 17:45:34,935] Epoch: 7 | Ph  | Train Loss: 0.220 | Val Loss: 0.219\n",
      "[2024-01-08 17:45:34,936] Epoch: 7 | Ending LR: 0.000138 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:35<00:00,  1.15s/it]\n",
      "[2024-01-08 17:50:13,230] Saving improved model after Val Loss improved from 0.23812 to 0.22846\n",
      "[2024-01-08 17:50:13,329] Epoch: 8 | FT  | Train Loss: 0.22938 | Val Loss: 0.22846\n",
      "[2024-01-08 17:50:13,331] Epoch: 8 | Amp | Train Loss: 0.0194 | Val Loss: 0.0191\n",
      "[2024-01-08 17:50:13,332] Epoch: 8 | Ph  | Train Loss: 0.210 | Val Loss: 0.209\n",
      "[2024-01-08 17:50:13,333] Epoch: 8 | Ending LR: 0.000108 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:35<00:00,  1.14s/it]\n",
      "[2024-01-08 17:54:50,700] Saving improved model after Val Loss improved from 0.22846 to 0.21986\n",
      "[2024-01-08 17:54:50,799] Epoch: 9 | FT  | Train Loss: 0.22197 | Val Loss: 0.21986\n",
      "[2024-01-08 17:54:50,800] Epoch: 9 | Amp | Train Loss: 0.0192 | Val Loss: 0.0177\n",
      "[2024-01-08 17:54:50,800] Epoch: 9 | Ph  | Train Loss: 0.203 | Val Loss: 0.202\n",
      "[2024-01-08 17:54:50,801] Epoch: 9 | Ending LR: 0.000077 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:34<00:00,  1.14s/it]\n",
      "[2024-01-08 17:59:27,885] Saving improved model after Val Loss improved from 0.21986 to 0.21693\n",
      "[2024-01-08 17:59:27,986] Epoch: 10 | FT  | Train Loss: 0.21448 | Val Loss: 0.21693\n",
      "[2024-01-08 17:59:27,987] Epoch: 10 | Amp | Train Loss: 0.0189 | Val Loss: 0.0185\n",
      "[2024-01-08 17:59:27,988] Epoch: 10 | Ph  | Train Loss: 0.196 | Val Loss: 0.198\n",
      "[2024-01-08 17:59:27,989] Epoch: 10 | Ending LR: 0.000047 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:34<00:00,  1.14s/it]\n",
      "[2024-01-08 18:04:05,397] Saving improved model after Val Loss improved from 0.21693 to 0.21220\n",
      "[2024-01-08 18:04:05,498] Epoch: 11 | FT  | Train Loss: 0.20880 | Val Loss: 0.21220\n",
      "[2024-01-08 18:04:05,499] Epoch: 11 | Amp | Train Loss: 0.0186 | Val Loss: 0.0177\n",
      "[2024-01-08 18:04:05,501] Epoch: 11 | Ph  | Train Loss: 0.190 | Val Loss: 0.195\n",
      "[2024-01-08 18:04:05,502] Epoch: 11 | Ending LR: 0.000022 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:44<00:00,  1.18s/it]\n",
      "[2024-01-08 18:08:52,202] Epoch: 12 | FT  | Train Loss: 0.20663 | Val Loss: 0.21414\n",
      "[2024-01-08 18:08:52,204] Epoch: 12 | Amp | Train Loss: 0.0185 | Val Loss: 0.0182\n",
      "[2024-01-08 18:08:52,205] Epoch: 12 | Ph  | Train Loss: 0.188 | Val Loss: 0.196\n",
      "[2024-01-08 18:08:52,205] Epoch: 12 | Ending LR: 0.000037 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:43<00:00,  1.17s/it]\n",
      "[2024-01-08 18:13:37,625] Epoch: 13 | FT  | Train Loss: 0.20702 | Val Loss: 0.21395\n",
      "[2024-01-08 18:13:37,626] Epoch: 13 | Amp | Train Loss: 0.0187 | Val Loss: 0.0180\n",
      "[2024-01-08 18:13:37,627] Epoch: 13 | Ph  | Train Loss: 0.188 | Val Loss: 0.196\n",
      "[2024-01-08 18:13:37,627] Epoch: 13 | Ending LR: 0.000052 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:35<00:00,  1.14s/it]\n",
      "[2024-01-08 18:18:15,073] Saving improved model after Val Loss improved from 0.21220 to 0.21098\n",
      "[2024-01-08 18:18:15,177] Epoch: 14 | FT  | Train Loss: 0.20737 | Val Loss: 0.21098\n",
      "[2024-01-08 18:18:15,178] Epoch: 14 | Amp | Train Loss: 0.0187 | Val Loss: 0.0181\n",
      "[2024-01-08 18:18:15,179] Epoch: 14 | Ph  | Train Loss: 0.189 | Val Loss: 0.193\n",
      "[2024-01-08 18:18:15,180] Epoch: 14 | Ending LR: 0.000067 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:38<00:00,  1.15s/it]\n",
      "[2024-01-08 18:22:55,643] Epoch: 15 | FT  | Train Loss: 0.20658 | Val Loss: 0.21487\n",
      "[2024-01-08 18:22:55,645] Epoch: 15 | Amp | Train Loss: 0.0189 | Val Loss: 0.0181\n",
      "[2024-01-08 18:22:55,646] Epoch: 15 | Ph  | Train Loss: 0.188 | Val Loss: 0.197\n",
      "[2024-01-08 18:22:55,647] Epoch: 15 | Ending LR: 0.000082 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:35<00:00,  1.14s/it]\n",
      "[2024-01-08 18:27:33,565] Epoch: 16 | FT  | Train Loss: 0.20434 | Val Loss: 0.21842\n",
      "[2024-01-08 18:27:33,567] Epoch: 16 | Amp | Train Loss: 0.0186 | Val Loss: 0.0173\n",
      "[2024-01-08 18:27:33,569] Epoch: 16 | Ph  | Train Loss: 0.186 | Val Loss: 0.201\n",
      "[2024-01-08 18:27:33,570] Epoch: 16 | Ending LR: 0.000097 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:34<00:00,  1.14s/it]\n",
      "[2024-01-08 18:32:10,464] Saving improved model after Val Loss improved from 0.21098 to 0.20990\n",
      "[2024-01-08 18:32:10,556] Epoch: 17 | FT  | Train Loss: 0.20493 | Val Loss: 0.20990\n",
      "[2024-01-08 18:32:10,557] Epoch: 17 | Amp | Train Loss: 0.0191 | Val Loss: 0.0180\n",
      "[2024-01-08 18:32:10,558] Epoch: 17 | Ph  | Train Loss: 0.186 | Val Loss: 0.192\n",
      "[2024-01-08 18:32:10,558] Epoch: 17 | Ending LR: 0.000108 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:35<00:00,  1.14s/it]\n",
      "[2024-01-08 18:36:48,567] Saving improved model after Val Loss improved from 0.20990 to 0.20512\n",
      "[2024-01-08 18:36:48,660] Epoch: 18 | FT  | Train Loss: 0.19946 | Val Loss: 0.20512\n",
      "[2024-01-08 18:36:48,662] Epoch: 18 | Amp | Train Loss: 0.0185 | Val Loss: 0.0171\n",
      "[2024-01-08 18:36:48,663] Epoch: 18 | Ph  | Train Loss: 0.181 | Val Loss: 0.188\n",
      "[2024-01-08 18:36:48,664] Epoch: 18 | Ending LR: 0.000093 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:35<00:00,  1.14s/it]\n",
      "[2024-01-08 18:41:26,394] Saving improved model after Val Loss improved from 0.20512 to 0.20125\n",
      "[2024-01-08 18:41:26,495] Epoch: 19 | FT  | Train Loss: 0.19405 | Val Loss: 0.20125\n",
      "[2024-01-08 18:41:26,496] Epoch: 19 | Amp | Train Loss: 0.0183 | Val Loss: 0.0184\n",
      "[2024-01-08 18:41:26,496] Epoch: 19 | Ph  | Train Loss: 0.176 | Val Loss: 0.183\n",
      "[2024-01-08 18:41:26,497] Epoch: 19 | Ending LR: 0.000077 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:41<00:00,  1.17s/it]\n",
      "[2024-01-08 18:46:10,046] Epoch: 20 | FT  | Train Loss: 0.18958 | Val Loss: 0.20302\n",
      "[2024-01-08 18:46:10,047] Epoch: 20 | Amp | Train Loss: 0.0181 | Val Loss: 0.0171\n",
      "[2024-01-08 18:46:10,048] Epoch: 20 | Ph  | Train Loss: 0.171 | Val Loss: 0.186\n",
      "[2024-01-08 18:46:10,048] Epoch: 20 | Ending LR: 0.000062 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:38<00:00,  1.16s/it]\n",
      "[2024-01-08 18:50:51,146] Saving improved model after Val Loss improved from 0.20125 to 0.19712\n",
      "[2024-01-08 18:50:51,240] Epoch: 21 | FT  | Train Loss: 0.18530 | Val Loss: 0.19712\n",
      "[2024-01-08 18:50:51,241] Epoch: 21 | Amp | Train Loss: 0.0177 | Val Loss: 0.0169\n",
      "[2024-01-08 18:50:51,242] Epoch: 21 | Ph  | Train Loss: 0.168 | Val Loss: 0.180\n",
      "[2024-01-08 18:50:51,242] Epoch: 21 | Ending LR: 0.000047 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:38<00:00,  1.16s/it]\n",
      "[2024-01-08 18:55:32,424] Saving improved model after Val Loss improved from 0.19712 to 0.19536\n",
      "[2024-01-08 18:55:32,523] Epoch: 22 | FT  | Train Loss: 0.18082 | Val Loss: 0.19536\n",
      "[2024-01-08 18:55:32,525] Epoch: 22 | Amp | Train Loss: 0.0175 | Val Loss: 0.0176\n",
      "[2024-01-08 18:55:32,527] Epoch: 22 | Ph  | Train Loss: 0.163 | Val Loss: 0.178\n",
      "[2024-01-08 18:55:32,528] Epoch: 22 | Ending LR: 0.000032 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:40<00:00,  1.16s/it]\n",
      "[2024-01-08 19:00:15,546] Saving improved model after Val Loss improved from 0.19536 to 0.19269\n",
      "[2024-01-08 19:00:15,644] Epoch: 23 | FT  | Train Loss: 0.17738 | Val Loss: 0.19269\n",
      "[2024-01-08 19:00:15,645] Epoch: 23 | Amp | Train Loss: 0.0173 | Val Loss: 0.0168\n",
      "[2024-01-08 19:00:15,646] Epoch: 23 | Ph  | Train Loss: 0.160 | Val Loss: 0.176\n",
      "[2024-01-08 19:00:15,646] Epoch: 23 | Ending LR: 0.000022 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:36<00:00,  1.15s/it]\n",
      "[2024-01-08 19:04:54,209] Epoch: 24 | FT  | Train Loss: 0.17650 | Val Loss: 0.19292\n",
      "[2024-01-08 19:04:54,210] Epoch: 24 | Amp | Train Loss: 0.0172 | Val Loss: 0.0167\n",
      "[2024-01-08 19:04:54,211] Epoch: 24 | Ph  | Train Loss: 0.159 | Val Loss: 0.176\n",
      "[2024-01-08 19:04:54,211] Epoch: 24 | Ending LR: 0.000029 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:35<00:00,  1.14s/it]\n",
      "[2024-01-08 19:09:31,753] Epoch: 25 | FT  | Train Loss: 0.17673 | Val Loss: 0.19446\n",
      "[2024-01-08 19:09:31,754] Epoch: 25 | Amp | Train Loss: 0.0173 | Val Loss: 0.0181\n",
      "[2024-01-08 19:09:31,755] Epoch: 25 | Ph  | Train Loss: 0.159 | Val Loss: 0.176\n",
      "[2024-01-08 19:09:31,756] Epoch: 25 | Ending LR: 0.000037 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:46<00:00,  1.19s/it]\n",
      "[2024-01-08 19:14:20,772] Epoch: 26 | FT  | Train Loss: 0.17670 | Val Loss: 0.19617\n",
      "[2024-01-08 19:14:20,774] Epoch: 26 | Amp | Train Loss: 0.0172 | Val Loss: 0.0185\n",
      "[2024-01-08 19:14:20,774] Epoch: 26 | Ph  | Train Loss: 0.160 | Val Loss: 0.178\n",
      "[2024-01-08 19:14:20,775] Epoch: 26 | Ending LR: 0.000044 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:45<00:00,  1.19s/it]\n",
      "[2024-01-08 19:19:08,979] Epoch: 27 | FT  | Train Loss: 0.17718 | Val Loss: 0.19319\n",
      "[2024-01-08 19:19:08,982] Epoch: 27 | Amp | Train Loss: 0.0174 | Val Loss: 0.0164\n",
      "[2024-01-08 19:19:08,982] Epoch: 27 | Ph  | Train Loss: 0.160 | Val Loss: 0.177\n",
      "[2024-01-08 19:19:08,983] Epoch: 27 | Ending LR: 0.000052 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:39<00:00,  1.16s/it]\n",
      "[2024-01-08 19:23:51,104] Epoch: 28 | FT  | Train Loss: 0.17609 | Val Loss: 0.19385\n",
      "[2024-01-08 19:23:51,105] Epoch: 28 | Amp | Train Loss: 0.0174 | Val Loss: 0.0163\n",
      "[2024-01-08 19:23:51,106] Epoch: 28 | Ph  | Train Loss: 0.159 | Val Loss: 0.177\n",
      "[2024-01-08 19:23:51,107] Epoch: 28 | Ending LR: 0.000059 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:37<00:00,  1.15s/it]\n",
      "[2024-01-08 19:28:30,925] Epoch: 29 | FT  | Train Loss: 0.17653 | Val Loss: 0.19422\n",
      "[2024-01-08 19:28:30,927] Epoch: 29 | Amp | Train Loss: 0.0174 | Val Loss: 0.0174\n",
      "[2024-01-08 19:28:30,928] Epoch: 29 | Ph  | Train Loss: 0.159 | Val Loss: 0.177\n",
      "[2024-01-08 19:28:30,928] Epoch: 29 | Ending LR: 0.000063 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:39<00:00,  1.16s/it]\n",
      "[2024-01-08 19:33:12,522] Saving improved model after Val Loss improved from 0.19269 to 0.19087\n",
      "[2024-01-08 19:33:12,618] Epoch: 30 | FT  | Train Loss: 0.17351 | Val Loss: 0.19087\n",
      "[2024-01-08 19:33:12,619] Epoch: 30 | Amp | Train Loss: 0.0171 | Val Loss: 0.0166\n",
      "[2024-01-08 19:33:12,620] Epoch: 30 | Ph  | Train Loss: 0.156 | Val Loss: 0.174\n",
      "[2024-01-08 19:33:12,620] Epoch: 30 | Ending LR: 0.000056 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:34<00:00,  1.14s/it]\n",
      "[2024-01-08 19:37:49,882] Saving improved model after Val Loss improved from 0.19087 to 0.18945\n",
      "[2024-01-08 19:37:49,988] Epoch: 31 | FT  | Train Loss: 0.16994 | Val Loss: 0.18945\n",
      "[2024-01-08 19:37:49,990] Epoch: 31 | Amp | Train Loss: 0.0169 | Val Loss: 0.0160\n",
      "[2024-01-08 19:37:49,991] Epoch: 31 | Ph  | Train Loss: 0.153 | Val Loss: 0.173\n",
      "[2024-01-08 19:37:49,992] Epoch: 31 | Ending LR: 0.000048 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:34<00:00,  1.14s/it]\n",
      "[2024-01-08 19:42:27,384] Epoch: 32 | FT  | Train Loss: 0.16755 | Val Loss: 0.19438\n",
      "[2024-01-08 19:42:27,388] Epoch: 32 | Amp | Train Loss: 0.0166 | Val Loss: 0.0215\n",
      "[2024-01-08 19:42:27,389] Epoch: 32 | Ph  | Train Loss: 0.151 | Val Loss: 0.173\n",
      "[2024-01-08 19:42:27,389] Epoch: 32 | Ending LR: 0.000040 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:36<00:00,  1.15s/it]\n",
      "[2024-01-08 19:47:05,840] Saving improved model after Val Loss improved from 0.18945 to 0.18753\n",
      "[2024-01-08 19:47:05,936] Epoch: 33 | FT  | Train Loss: 0.16467 | Val Loss: 0.18753\n",
      "[2024-01-08 19:47:05,938] Epoch: 33 | Amp | Train Loss: 0.0165 | Val Loss: 0.0159\n",
      "[2024-01-08 19:47:05,939] Epoch: 33 | Ph  | Train Loss: 0.148 | Val Loss: 0.172\n",
      "[2024-01-08 19:47:05,940] Epoch: 33 | Ending LR: 0.000033 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:42<00:00,  1.17s/it]\n",
      "[2024-01-08 19:51:50,540] Saving improved model after Val Loss improved from 0.18753 to 0.18641\n",
      "[2024-01-08 19:51:50,648] Epoch: 34 | FT  | Train Loss: 0.16230 | Val Loss: 0.18641\n",
      "[2024-01-08 19:51:50,650] Epoch: 34 | Amp | Train Loss: 0.0163 | Val Loss: 0.0158\n",
      "[2024-01-08 19:51:50,651] Epoch: 34 | Ph  | Train Loss: 0.146 | Val Loss: 0.171\n",
      "[2024-01-08 19:51:50,652] Epoch: 34 | Ending LR: 0.000025 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:44<00:00,  1.18s/it]\n",
      "[2024-01-08 19:56:37,821] Saving improved model after Val Loss improved from 0.18641 to 0.18517\n",
      "[2024-01-08 19:56:37,923] Epoch: 35 | FT  | Train Loss: 0.16012 | Val Loss: 0.18517\n",
      "[2024-01-08 19:56:37,924] Epoch: 35 | Amp | Train Loss: 0.0161 | Val Loss: 0.0158\n",
      "[2024-01-08 19:56:37,925] Epoch: 35 | Ph  | Train Loss: 0.144 | Val Loss: 0.169\n",
      "[2024-01-08 19:56:37,925] Epoch: 35 | Ending LR: 0.000021 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:35<00:00,  1.14s/it]\n",
      "[2024-01-08 20:01:15,732] Epoch: 36 | FT  | Train Loss: 0.15971 | Val Loss: 0.18681\n",
      "[2024-01-08 20:01:15,733] Epoch: 36 | Amp | Train Loss: 0.0161 | Val Loss: 0.0160\n",
      "[2024-01-08 20:01:15,734] Epoch: 36 | Ph  | Train Loss: 0.144 | Val Loss: 0.171\n",
      "[2024-01-08 20:01:15,734] Epoch: 36 | Ending LR: 0.000025 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:35<00:00,  1.14s/it]\n",
      "[2024-01-08 20:05:53,560] Epoch: 37 | FT  | Train Loss: 0.15974 | Val Loss: 0.18547\n",
      "[2024-01-08 20:05:53,561] Epoch: 37 | Amp | Train Loss: 0.0161 | Val Loss: 0.0157\n",
      "[2024-01-08 20:05:53,562] Epoch: 37 | Ph  | Train Loss: 0.144 | Val Loss: 0.170\n",
      "[2024-01-08 20:05:53,562] Epoch: 37 | Ending LR: 0.000029 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:38<00:00,  1.16s/it]\n",
      "[2024-01-08 20:10:34,625] Epoch: 38 | FT  | Train Loss: 0.15969 | Val Loss: 0.18587\n",
      "[2024-01-08 20:10:34,626] Epoch: 38 | Amp | Train Loss: 0.0161 | Val Loss: 0.0159\n",
      "[2024-01-08 20:10:34,627] Epoch: 38 | Ph  | Train Loss: 0.144 | Val Loss: 0.170\n",
      "[2024-01-08 20:10:34,628] Epoch: 38 | Ending LR: 0.000032 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:37<00:00,  1.15s/it]\n",
      "[2024-01-08 20:15:14,408] Epoch: 39 | FT  | Train Loss: 0.15918 | Val Loss: 0.18759\n",
      "[2024-01-08 20:15:14,409] Epoch: 39 | Amp | Train Loss: 0.0160 | Val Loss: 0.0175\n",
      "[2024-01-08 20:15:14,410] Epoch: 39 | Ph  | Train Loss: 0.143 | Val Loss: 0.170\n",
      "[2024-01-08 20:15:14,410] Epoch: 39 | Ending LR: 0.000036 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:40<00:00,  1.16s/it]\n",
      "[2024-01-08 20:19:57,235] Epoch: 40 | FT  | Train Loss: 0.15904 | Val Loss: 0.18741\n",
      "[2024-01-08 20:19:57,236] Epoch: 40 | Amp | Train Loss: 0.0160 | Val Loss: 0.0157\n",
      "[2024-01-08 20:19:57,237] Epoch: 40 | Ph  | Train Loss: 0.143 | Val Loss: 0.172\n",
      "[2024-01-08 20:19:57,238] Epoch: 40 | Ending LR: 0.000040 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:39<00:00,  1.16s/it]\n",
      "[2024-01-08 20:24:38,834] Epoch: 41 | FT  | Train Loss: 0.15918 | Val Loss: 0.18540\n",
      "[2024-01-08 20:24:38,835] Epoch: 41 | Amp | Train Loss: 0.0160 | Val Loss: 0.0157\n",
      "[2024-01-08 20:24:38,836] Epoch: 41 | Ph  | Train Loss: 0.143 | Val Loss: 0.170\n",
      "[2024-01-08 20:24:38,837] Epoch: 41 | Ending LR: 0.000041 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:36<00:00,  1.15s/it]\n",
      "[2024-01-08 20:29:17,216] Epoch: 42 | FT  | Train Loss: 0.15724 | Val Loss: 0.18548\n",
      "[2024-01-08 20:29:17,217] Epoch: 42 | Amp | Train Loss: 0.0157 | Val Loss: 0.0158\n",
      "[2024-01-08 20:29:17,218] Epoch: 42 | Ph  | Train Loss: 0.142 | Val Loss: 0.170\n",
      "[2024-01-08 20:29:17,218] Epoch: 42 | Ending LR: 0.000037 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:34<00:00,  1.14s/it]\n",
      "[2024-01-08 20:33:53,721] Saving improved model after Val Loss improved from 0.18517 to 0.18510\n",
      "[2024-01-08 20:33:53,817] Epoch: 43 | FT  | Train Loss: 0.15543 | Val Loss: 0.18510\n",
      "[2024-01-08 20:33:53,817] Epoch: 43 | Amp | Train Loss: 0.0157 | Val Loss: 0.0159\n",
      "[2024-01-08 20:33:53,818] Epoch: 43 | Ph  | Train Loss: 0.140 | Val Loss: 0.169\n",
      "[2024-01-08 20:33:53,818] Epoch: 43 | Ending LR: 0.000034 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:33<00:00,  1.13s/it]\n",
      "[2024-01-08 20:38:29,535] Saving improved model after Val Loss improved from 0.18510 to 0.18457\n",
      "[2024-01-08 20:38:29,633] Epoch: 44 | FT  | Train Loss: 0.15360 | Val Loss: 0.18457\n",
      "[2024-01-08 20:38:29,634] Epoch: 44 | Amp | Train Loss: 0.0155 | Val Loss: 0.0169\n",
      "[2024-01-08 20:38:29,635] Epoch: 44 | Ph  | Train Loss: 0.138 | Val Loss: 0.168\n",
      "[2024-01-08 20:38:29,635] Epoch: 44 | Ending LR: 0.000030 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:35<00:00,  1.14s/it]\n",
      "[2024-01-08 20:43:07,953] Saving improved model after Val Loss improved from 0.18457 to 0.18403\n",
      "[2024-01-08 20:43:08,081] Epoch: 45 | FT  | Train Loss: 0.15218 | Val Loss: 0.18403\n",
      "[2024-01-08 20:43:08,083] Epoch: 45 | Amp | Train Loss: 0.0153 | Val Loss: 0.0164\n",
      "[2024-01-08 20:43:08,084] Epoch: 45 | Ph  | Train Loss: 0.137 | Val Loss: 0.168\n",
      "[2024-01-08 20:43:08,085] Epoch: 45 | Ending LR: 0.000026 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:34<00:00,  1.14s/it]\n",
      "[2024-01-08 20:47:45,162] Saving improved model after Val Loss improved from 0.18403 to 0.18233\n",
      "[2024-01-08 20:47:45,268] Epoch: 46 | FT  | Train Loss: 0.15024 | Val Loss: 0.18233\n",
      "[2024-01-08 20:47:45,269] Epoch: 46 | Amp | Train Loss: 0.0153 | Val Loss: 0.0154\n",
      "[2024-01-08 20:47:45,269] Epoch: 46 | Ph  | Train Loss: 0.135 | Val Loss: 0.167\n",
      "[2024-01-08 20:47:45,270] Epoch: 46 | Ending LR: 0.000022 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:37<00:00,  1.15s/it]\n",
      "[2024-01-08 20:52:24,757] Epoch: 47 | FT  | Train Loss: 0.14923 | Val Loss: 0.18273\n",
      "[2024-01-08 20:52:24,758] Epoch: 47 | Amp | Train Loss: 0.0151 | Val Loss: 0.0155\n",
      "[2024-01-08 20:52:24,759] Epoch: 47 | Ph  | Train Loss: 0.134 | Val Loss: 0.167\n",
      "[2024-01-08 20:52:24,760] Epoch: 47 | Ending LR: 0.000021 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:35<00:00,  1.14s/it]\n",
      "[2024-01-08 20:57:02,469] Epoch: 48 | FT  | Train Loss: 0.14884 | Val Loss: 0.18715\n",
      "[2024-01-08 20:57:02,470] Epoch: 48 | Amp | Train Loss: 0.0151 | Val Loss: 0.0159\n",
      "[2024-01-08 20:57:02,470] Epoch: 48 | Ph  | Train Loss: 0.134 | Val Loss: 0.171\n",
      "[2024-01-08 20:57:02,471] Epoch: 48 | Ending LR: 0.000023 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:35<00:00,  1.14s/it]\n",
      "[2024-01-08 21:01:39,943] Epoch: 49 | FT  | Train Loss: 0.14882 | Val Loss: 0.18381\n",
      "[2024-01-08 21:01:39,944] Epoch: 49 | Amp | Train Loss: 0.0150 | Val Loss: 0.0155\n",
      "[2024-01-08 21:01:39,945] Epoch: 49 | Ph  | Train Loss: 0.134 | Val Loss: 0.168\n",
      "[2024-01-08 21:01:39,946] Epoch: 49 | Ending LR: 0.000025 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:45<00:00,  1.18s/it]\n",
      "[2024-01-08 21:06:27,618] Saving improved model after Val Loss improved from 0.18233 to 0.18232\n",
      "[2024-01-08 21:06:27,721] Epoch: 50 | FT  | Train Loss: 0.14884 | Val Loss: 0.18232\n",
      "[2024-01-08 21:06:27,722] Epoch: 50 | Amp | Train Loss: 0.0151 | Val Loss: 0.0154\n",
      "[2024-01-08 21:06:27,723] Epoch: 50 | Ph  | Train Loss: 0.134 | Val Loss: 0.167\n",
      "[2024-01-08 21:06:27,724] Epoch: 50 | Ending LR: 0.000026 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:37<00:00,  1.15s/it]\n",
      "[2024-01-08 21:11:07,716] Epoch: 51 | FT  | Train Loss: 0.14782 | Val Loss: 0.18328\n",
      "[2024-01-08 21:11:07,718] Epoch: 51 | Amp | Train Loss: 0.0150 | Val Loss: 0.0155\n",
      "[2024-01-08 21:11:07,719] Epoch: 51 | Ph  | Train Loss: 0.133 | Val Loss: 0.168\n",
      "[2024-01-08 21:11:07,720] Epoch: 51 | Ending LR: 0.000028 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:33<00:00,  1.14s/it]\n",
      "[2024-01-08 21:15:44,022] Epoch: 52 | FT  | Train Loss: 0.14798 | Val Loss: 0.18333\n",
      "[2024-01-08 21:15:44,023] Epoch: 52 | Amp | Train Loss: 0.0151 | Val Loss: 0.0156\n",
      "[2024-01-08 21:15:44,024] Epoch: 52 | Ph  | Train Loss: 0.133 | Val Loss: 0.168\n",
      "[2024-01-08 21:15:44,024] Epoch: 52 | Ending LR: 0.000030 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:36<00:00,  1.15s/it]\n",
      "[2024-01-08 21:20:22,861] Epoch: 53 | FT  | Train Loss: 0.14729 | Val Loss: 0.18487\n",
      "[2024-01-08 21:20:22,863] Epoch: 53 | Amp | Train Loss: 0.0148 | Val Loss: 0.0159\n",
      "[2024-01-08 21:20:22,864] Epoch: 53 | Ph  | Train Loss: 0.132 | Val Loss: 0.169\n",
      "[2024-01-08 21:20:22,865] Epoch: 53 | Ending LR: 0.000030 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:35<00:00,  1.14s/it]\n",
      "[2024-01-08 21:25:00,594] Epoch: 54 | FT  | Train Loss: 0.14639 | Val Loss: 0.18264\n",
      "[2024-01-08 21:25:00,595] Epoch: 54 | Amp | Train Loss: 0.0147 | Val Loss: 0.0162\n",
      "[2024-01-08 21:25:00,596] Epoch: 54 | Ph  | Train Loss: 0.132 | Val Loss: 0.166\n",
      "[2024-01-08 21:25:00,596] Epoch: 54 | Ending LR: 0.000029 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:34<00:00,  1.14s/it]\n",
      "[2024-01-08 21:29:37,643] Saving improved model after Val Loss improved from 0.18232 to 0.18219\n",
      "[2024-01-08 21:29:37,730] Epoch: 55 | FT  | Train Loss: 0.14537 | Val Loss: 0.18219\n",
      "[2024-01-08 21:29:37,731] Epoch: 55 | Amp | Train Loss: 0.0146 | Val Loss: 0.0155\n",
      "[2024-01-08 21:29:37,731] Epoch: 55 | Ph  | Train Loss: 0.131 | Val Loss: 0.167\n",
      "[2024-01-08 21:29:37,732] Epoch: 55 | Ending LR: 0.000027 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:34<00:00,  1.14s/it]\n",
      "[2024-01-08 21:34:14,340] Epoch: 56 | FT  | Train Loss: 0.14400 | Val Loss: 0.18254\n",
      "[2024-01-08 21:34:14,341] Epoch: 56 | Amp | Train Loss: 0.0147 | Val Loss: 0.0158\n",
      "[2024-01-08 21:34:14,341] Epoch: 56 | Ph  | Train Loss: 0.129 | Val Loss: 0.167\n",
      "[2024-01-08 21:34:14,342] Epoch: 56 | Ending LR: 0.000025 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:38<00:00,  1.16s/it]\n",
      "[2024-01-08 21:38:55,253] Saving improved model after Val Loss improved from 0.18219 to 0.18169\n",
      "[2024-01-08 21:38:55,383] Epoch: 57 | FT  | Train Loss: 0.14312 | Val Loss: 0.18169\n",
      "[2024-01-08 21:38:55,384] Epoch: 57 | Amp | Train Loss: 0.0144 | Val Loss: 0.0157\n",
      "[2024-01-08 21:38:55,386] Epoch: 57 | Ph  | Train Loss: 0.129 | Val Loss: 0.166\n",
      "[2024-01-08 21:38:55,387] Epoch: 57 | Ending LR: 0.000023 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:36<00:00,  1.15s/it]\n",
      "[2024-01-08 21:43:34,154] Epoch: 58 | FT  | Train Loss: 0.14218 | Val Loss: 0.18308\n",
      "[2024-01-08 21:43:34,156] Epoch: 58 | Amp | Train Loss: 0.0143 | Val Loss: 0.0156\n",
      "[2024-01-08 21:43:34,156] Epoch: 58 | Ph  | Train Loss: 0.128 | Val Loss: 0.167\n",
      "[2024-01-08 21:43:34,157] Epoch: 58 | Ending LR: 0.000021 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 241/241 [04:36<00:00,  1.15s/it]\n",
      "[2024-01-08 21:48:12,594] Epoch: 59 | FT  | Train Loss: 0.14140 | Val Loss: 0.18262\n",
      "[2024-01-08 21:48:12,595] Epoch: 59 | Amp | Train Loss: 0.0143 | Val Loss: 0.0163\n",
      "[2024-01-08 21:48:12,596] Epoch: 59 | Ph  | Train Loss: 0.127 | Val Loss: 0.166\n",
      "[2024-01-08 21:48:12,596] Epoch: 59 | Ending LR: 0.000020 \n",
      "[2024-01-08 21:48:12,696] Decimating dataset to 0.8 of the original size...\n",
      "[2024-01-08 21:48:12,833] Using DataParallel with 2 devices.\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:03<00:00,  1.13s/it]\n",
      "[2024-01-08 21:52:18,259] Saving improved model after Val Loss improved from inf to 0.62878\n",
      "[2024-01-08 21:52:18,317] Epoch: 0 | FT  | Train Loss: 0.68882 | Val Loss: 0.62878\n",
      "[2024-01-08 21:52:18,317] Epoch: 0 | Amp | Train Loss: 0.1163 | Val Loss: 0.0535\n",
      "[2024-01-08 21:52:18,318] Epoch: 0 | Ph  | Train Loss: 0.573 | Val Loss: 0.575\n",
      "[2024-01-08 21:52:18,318] Epoch: 0 | Ending LR: 0.000050 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:04<00:00,  1.14s/it]\n",
      "[2024-01-08 21:56:24,678] Saving improved model after Val Loss improved from 0.62878 to 0.53941\n",
      "[2024-01-08 21:56:24,760] Epoch: 1 | FT  | Train Loss: 0.56072 | Val Loss: 0.53941\n",
      "[2024-01-08 21:56:24,761] Epoch: 1 | Amp | Train Loss: 0.0234 | Val Loss: 0.0254\n",
      "[2024-01-08 21:56:24,761] Epoch: 1 | Ph  | Train Loss: 0.537 | Val Loss: 0.514\n",
      "[2024-01-08 21:56:24,761] Epoch: 1 | Ending LR: 0.000081 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:08<00:00,  1.15s/it]\n",
      "[2024-01-08 22:00:35,074] Saving improved model after Val Loss improved from 0.53941 to 0.42671\n",
      "[2024-01-08 22:00:35,174] Epoch: 2 | FT  | Train Loss: 0.43231 | Val Loss: 0.42671\n",
      "[2024-01-08 22:00:35,175] Epoch: 2 | Amp | Train Loss: 0.0221 | Val Loss: 0.0436\n",
      "[2024-01-08 22:00:35,176] Epoch: 2 | Ph  | Train Loss: 0.410 | Val Loss: 0.383\n",
      "[2024-01-08 22:00:35,177] Epoch: 2 | Ending LR: 0.000111 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:13<00:00,  1.18s/it]\n",
      "[2024-01-08 22:04:50,795] Saving improved model after Val Loss improved from 0.42671 to 0.39365\n",
      "[2024-01-08 22:04:50,889] Epoch: 3 | FT  | Train Loss: 0.34745 | Val Loss: 0.39365\n",
      "[2024-01-08 22:04:50,891] Epoch: 3 | Amp | Train Loss: 0.0214 | Val Loss: 0.0290\n",
      "[2024-01-08 22:04:50,892] Epoch: 3 | Ph  | Train Loss: 0.326 | Val Loss: 0.365\n",
      "[2024-01-08 22:04:50,893] Epoch: 3 | Ending LR: 0.000142 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:14<00:00,  1.19s/it]\n",
      "[2024-01-08 22:09:08,012] Saving improved model after Val Loss improved from 0.39365 to 0.33145\n",
      "[2024-01-08 22:09:08,108] Epoch: 4 | FT  | Train Loss: 0.30361 | Val Loss: 0.33145\n",
      "[2024-01-08 22:09:08,109] Epoch: 4 | Amp | Train Loss: 0.0210 | Val Loss: 0.0255\n",
      "[2024-01-08 22:09:08,110] Epoch: 4 | Ph  | Train Loss: 0.283 | Val Loss: 0.306\n",
      "[2024-01-08 22:09:08,111] Epoch: 4 | Ending LR: 0.000172 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:08<00:00,  1.16s/it]\n",
      "[2024-01-08 22:13:18,795] Saving improved model after Val Loss improved from 0.33145 to 0.30048\n",
      "[2024-01-08 22:13:18,907] Epoch: 5 | FT  | Train Loss: 0.27739 | Val Loss: 0.30048\n",
      "[2024-01-08 22:13:18,909] Epoch: 5 | Amp | Train Loss: 0.0203 | Val Loss: 0.0338\n",
      "[2024-01-08 22:13:18,910] Epoch: 5 | Ph  | Train Loss: 0.257 | Val Loss: 0.267\n",
      "[2024-01-08 22:13:18,911] Epoch: 5 | Ending LR: 0.000197 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:04<00:00,  1.14s/it]\n",
      "[2024-01-08 22:17:25,988] Saving improved model after Val Loss improved from 0.30048 to 0.28034\n",
      "[2024-01-08 22:17:26,091] Epoch: 6 | FT  | Train Loss: 0.25778 | Val Loss: 0.28034\n",
      "[2024-01-08 22:17:26,092] Epoch: 6 | Amp | Train Loss: 0.0203 | Val Loss: 0.0260\n",
      "[2024-01-08 22:17:26,093] Epoch: 6 | Ph  | Train Loss: 0.237 | Val Loss: 0.254\n",
      "[2024-01-08 22:17:26,094] Epoch: 6 | Ending LR: 0.000167 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:04<00:00,  1.14s/it]\n",
      "[2024-01-08 22:21:32,732] Saving improved model after Val Loss improved from 0.28034 to 0.26067\n",
      "[2024-01-08 22:21:32,838] Epoch: 7 | FT  | Train Loss: 0.24405 | Val Loss: 0.26067\n",
      "[2024-01-08 22:21:32,839] Epoch: 7 | Amp | Train Loss: 0.0202 | Val Loss: 0.0248\n",
      "[2024-01-08 22:21:32,839] Epoch: 7 | Ph  | Train Loss: 0.224 | Val Loss: 0.236\n",
      "[2024-01-08 22:21:32,840] Epoch: 7 | Ending LR: 0.000137 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:03<00:00,  1.13s/it]\n",
      "[2024-01-08 22:25:38,188] Epoch: 8 | FT  | Train Loss: 0.23352 | Val Loss: 0.26711\n",
      "[2024-01-08 22:25:38,190] Epoch: 8 | Amp | Train Loss: 0.0193 | Val Loss: 0.0238\n",
      "[2024-01-08 22:25:38,190] Epoch: 8 | Ph  | Train Loss: 0.214 | Val Loss: 0.243\n",
      "[2024-01-08 22:25:38,191] Epoch: 8 | Ending LR: 0.000106 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:15<00:00,  1.19s/it]\n",
      "[2024-01-08 22:29:55,430] Saving improved model after Val Loss improved from 0.26067 to 0.25694\n",
      "[2024-01-08 22:29:55,524] Epoch: 9 | FT  | Train Loss: 0.22598 | Val Loss: 0.25694\n",
      "[2024-01-08 22:29:55,525] Epoch: 9 | Amp | Train Loss: 0.0190 | Val Loss: 0.0314\n",
      "[2024-01-08 22:29:55,526] Epoch: 9 | Ph  | Train Loss: 0.207 | Val Loss: 0.226\n",
      "[2024-01-08 22:29:55,526] Epoch: 9 | Ending LR: 0.000076 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:14<00:00,  1.18s/it]\n",
      "[2024-01-08 22:34:11,723] Saving improved model after Val Loss improved from 0.25694 to 0.24240\n",
      "[2024-01-08 22:34:11,800] Epoch: 10 | FT  | Train Loss: 0.21918 | Val Loss: 0.24240\n",
      "[2024-01-08 22:34:11,801] Epoch: 10 | Amp | Train Loss: 0.0191 | Val Loss: 0.0237\n",
      "[2024-01-08 22:34:11,802] Epoch: 10 | Ph  | Train Loss: 0.200 | Val Loss: 0.219\n",
      "[2024-01-08 22:34:11,804] Epoch: 10 | Ending LR: 0.000045 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:06<00:00,  1.15s/it]\n",
      "[2024-01-08 22:38:20,916] Saving improved model after Val Loss improved from 0.24240 to 0.22935\n",
      "[2024-01-08 22:38:21,013] Epoch: 11 | FT  | Train Loss: 0.21268 | Val Loss: 0.22935\n",
      "[2024-01-08 22:38:21,014] Epoch: 11 | Amp | Train Loss: 0.0186 | Val Loss: 0.0236\n",
      "[2024-01-08 22:38:21,014] Epoch: 11 | Ph  | Train Loss: 0.194 | Val Loss: 0.206\n",
      "[2024-01-08 22:38:21,015] Epoch: 11 | Ending LR: 0.000023 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:04<00:00,  1.14s/it]\n",
      "[2024-01-08 22:42:27,571] Epoch: 12 | FT  | Train Loss: 0.21057 | Val Loss: 0.23820\n",
      "[2024-01-08 22:42:27,572] Epoch: 12 | Amp | Train Loss: 0.0185 | Val Loss: 0.0271\n",
      "[2024-01-08 22:42:27,573] Epoch: 12 | Ph  | Train Loss: 0.192 | Val Loss: 0.211\n",
      "[2024-01-08 22:42:27,573] Epoch: 12 | Ending LR: 0.000038 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:02<00:00,  1.13s/it]\n",
      "[2024-01-08 22:46:32,296] Epoch: 13 | FT  | Train Loss: 0.21126 | Val Loss: 0.23834\n",
      "[2024-01-08 22:46:32,297] Epoch: 13 | Amp | Train Loss: 0.0186 | Val Loss: 0.0236\n",
      "[2024-01-08 22:46:32,297] Epoch: 13 | Ph  | Train Loss: 0.193 | Val Loss: 0.215\n",
      "[2024-01-08 22:46:32,298] Epoch: 13 | Ending LR: 0.000053 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:05<00:00,  1.14s/it]\n",
      "[2024-01-08 22:50:40,336] Epoch: 14 | FT  | Train Loss: 0.21165 | Val Loss: 0.24934\n",
      "[2024-01-08 22:50:40,337] Epoch: 14 | Amp | Train Loss: 0.0187 | Val Loss: 0.0237\n",
      "[2024-01-08 22:50:40,338] Epoch: 14 | Ph  | Train Loss: 0.193 | Val Loss: 0.226\n",
      "[2024-01-08 22:50:40,339] Epoch: 14 | Ending LR: 0.000068 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:02<00:00,  1.13s/it]\n",
      "[2024-01-08 22:54:44,642] Epoch: 15 | FT  | Train Loss: 0.21067 | Val Loss: 0.24990\n",
      "[2024-01-08 22:54:44,643] Epoch: 15 | Amp | Train Loss: 0.0185 | Val Loss: 0.0317\n",
      "[2024-01-08 22:54:44,644] Epoch: 15 | Ph  | Train Loss: 0.192 | Val Loss: 0.218\n",
      "[2024-01-08 22:54:44,644] Epoch: 15 | Ending LR: 0.000083 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:08<00:00,  1.15s/it]\n",
      "[2024-01-08 22:58:55,047] Epoch: 16 | FT  | Train Loss: 0.21047 | Val Loss: 0.24205\n",
      "[2024-01-08 22:58:55,049] Epoch: 16 | Amp | Train Loss: 0.0192 | Val Loss: 0.0259\n",
      "[2024-01-08 22:58:55,050] Epoch: 16 | Ph  | Train Loss: 0.191 | Val Loss: 0.216\n",
      "[2024-01-08 22:58:55,051] Epoch: 16 | Ending LR: 0.000099 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:09<00:00,  1.16s/it]\n",
      "[2024-01-08 23:03:06,486] Epoch: 17 | FT  | Train Loss: 0.20877 | Val Loss: 0.23676\n",
      "[2024-01-08 23:03:06,489] Epoch: 17 | Amp | Train Loss: 0.0191 | Val Loss: 0.0242\n",
      "[2024-01-08 23:03:06,490] Epoch: 17 | Ph  | Train Loss: 0.190 | Val Loss: 0.213\n",
      "[2024-01-08 23:03:06,491] Epoch: 17 | Ending LR: 0.000106 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:03<00:00,  1.13s/it]\n",
      "[2024-01-08 23:07:11,611] Epoch: 18 | FT  | Train Loss: 0.20415 | Val Loss: 0.23328\n",
      "[2024-01-08 23:07:11,613] Epoch: 18 | Amp | Train Loss: 0.0186 | Val Loss: 0.0232\n",
      "[2024-01-08 23:07:11,613] Epoch: 18 | Ph  | Train Loss: 0.186 | Val Loss: 0.210\n",
      "[2024-01-08 23:07:11,614] Epoch: 18 | Ending LR: 0.000091 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:01<00:00,  1.12s/it]\n",
      "[2024-01-08 23:11:15,590] Epoch: 19 | FT  | Train Loss: 0.19915 | Val Loss: 0.23123\n",
      "[2024-01-08 23:11:15,591] Epoch: 19 | Amp | Train Loss: 0.0185 | Val Loss: 0.0229\n",
      "[2024-01-08 23:11:15,592] Epoch: 19 | Ph  | Train Loss: 0.181 | Val Loss: 0.208\n",
      "[2024-01-08 23:11:15,592] Epoch: 19 | Ending LR: 0.000076 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:01<00:00,  1.12s/it]\n",
      "[2024-01-08 23:15:19,170] Saving improved model after Val Loss improved from 0.22935 to 0.21783\n",
      "[2024-01-08 23:15:19,276] Epoch: 20 | FT  | Train Loss: 0.19345 | Val Loss: 0.21783\n",
      "[2024-01-08 23:15:19,277] Epoch: 20 | Amp | Train Loss: 0.0180 | Val Loss: 0.0229\n",
      "[2024-01-08 23:15:19,277] Epoch: 20 | Ph  | Train Loss: 0.175 | Val Loss: 0.195\n",
      "[2024-01-08 23:15:19,277] Epoch: 20 | Ending LR: 0.000061 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:04<00:00,  1.14s/it]\n",
      "[2024-01-08 23:19:25,759] Epoch: 21 | FT  | Train Loss: 0.18920 | Val Loss: 0.22132\n",
      "[2024-01-08 23:19:25,760] Epoch: 21 | Amp | Train Loss: 0.0179 | Val Loss: 0.0230\n",
      "[2024-01-08 23:19:25,761] Epoch: 21 | Ph  | Train Loss: 0.171 | Val Loss: 0.198\n",
      "[2024-01-08 23:19:25,762] Epoch: 21 | Ending LR: 0.000045 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:03<00:00,  1.13s/it]\n",
      "[2024-01-08 23:23:31,021] Saving improved model after Val Loss improved from 0.21783 to 0.21558\n",
      "[2024-01-08 23:23:31,117] Epoch: 22 | FT  | Train Loss: 0.18544 | Val Loss: 0.21558\n",
      "[2024-01-08 23:23:31,118] Epoch: 22 | Amp | Train Loss: 0.0176 | Val Loss: 0.0228\n",
      "[2024-01-08 23:23:31,118] Epoch: 22 | Ph  | Train Loss: 0.168 | Val Loss: 0.193\n",
      "[2024-01-08 23:23:31,119] Epoch: 22 | Ending LR: 0.000030 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:02<00:00,  1.13s/it]\n",
      "[2024-01-08 23:27:35,666] Saving improved model after Val Loss improved from 0.21558 to 0.21502\n",
      "[2024-01-08 23:27:35,762] Epoch: 23 | FT  | Train Loss: 0.18149 | Val Loss: 0.21502\n",
      "[2024-01-08 23:27:35,764] Epoch: 23 | Amp | Train Loss: 0.0174 | Val Loss: 0.0227\n",
      "[2024-01-08 23:27:35,765] Epoch: 23 | Ph  | Train Loss: 0.164 | Val Loss: 0.192\n",
      "[2024-01-08 23:27:35,766] Epoch: 23 | Ending LR: 0.000023 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:07<00:00,  1.15s/it]\n",
      "[2024-01-08 23:31:45,783] Epoch: 24 | FT  | Train Loss: 0.18087 | Val Loss: 0.21565\n",
      "[2024-01-08 23:31:45,784] Epoch: 24 | Amp | Train Loss: 0.0174 | Val Loss: 0.0243\n",
      "[2024-01-08 23:31:45,785] Epoch: 24 | Ph  | Train Loss: 0.163 | Val Loss: 0.191\n",
      "[2024-01-08 23:31:45,786] Epoch: 24 | Ending LR: 0.000030 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:11<00:00,  1.17s/it]\n",
      "[2024-01-08 23:35:59,400] Epoch: 25 | FT  | Train Loss: 0.18163 | Val Loss: 0.21685\n",
      "[2024-01-08 23:35:59,401] Epoch: 25 | Amp | Train Loss: 0.0175 | Val Loss: 0.0226\n",
      "[2024-01-08 23:35:59,402] Epoch: 25 | Ph  | Train Loss: 0.164 | Val Loss: 0.194\n",
      "[2024-01-08 23:35:59,402] Epoch: 25 | Ending LR: 0.000038 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:42<00:00,  1.32s/it]\n",
      "[2024-01-08 23:40:44,903] Saving improved model after Val Loss improved from 0.21502 to 0.21346\n",
      "[2024-01-08 23:40:45,019] Epoch: 26 | FT  | Train Loss: 0.18150 | Val Loss: 0.21346\n",
      "[2024-01-08 23:40:45,021] Epoch: 26 | Amp | Train Loss: 0.0175 | Val Loss: 0.0227\n",
      "[2024-01-08 23:40:45,022] Epoch: 26 | Ph  | Train Loss: 0.164 | Val Loss: 0.191\n",
      "[2024-01-08 23:40:45,023] Epoch: 26 | Ending LR: 0.000045 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:37<00:00,  1.29s/it]\n",
      "[2024-01-08 23:45:24,796] Epoch: 27 | FT  | Train Loss: 0.18185 | Val Loss: 0.22485\n",
      "[2024-01-08 23:45:24,797] Epoch: 27 | Amp | Train Loss: 0.0175 | Val Loss: 0.0244\n",
      "[2024-01-08 23:45:24,798] Epoch: 27 | Ph  | Train Loss: 0.164 | Val Loss: 0.200\n",
      "[2024-01-08 23:45:24,798] Epoch: 27 | Ending LR: 0.000053 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:30<00:00,  1.26s/it]\n",
      "[2024-01-08 23:49:57,462] Epoch: 28 | FT  | Train Loss: 0.18068 | Val Loss: 0.21907\n",
      "[2024-01-08 23:49:57,464] Epoch: 28 | Amp | Train Loss: 0.0173 | Val Loss: 0.0229\n",
      "[2024-01-08 23:49:57,464] Epoch: 28 | Ph  | Train Loss: 0.163 | Val Loss: 0.196\n",
      "[2024-01-08 23:49:57,465] Epoch: 28 | Ending LR: 0.000061 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:28<00:00,  1.25s/it]\n",
      "[2024-01-08 23:54:28,734] Epoch: 29 | FT  | Train Loss: 0.18054 | Val Loss: 0.22706\n",
      "[2024-01-08 23:54:28,735] Epoch: 29 | Amp | Train Loss: 0.0175 | Val Loss: 0.0254\n",
      "[2024-01-08 23:54:28,736] Epoch: 29 | Ph  | Train Loss: 0.163 | Val Loss: 0.202\n",
      "[2024-01-08 23:54:28,737] Epoch: 29 | Ending LR: 0.000062 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:33<00:00,  1.27s/it]\n",
      "[2024-01-08 23:59:04,530] Epoch: 30 | FT  | Train Loss: 0.17775 | Val Loss: 0.21465\n",
      "[2024-01-08 23:59:04,532] Epoch: 30 | Amp | Train Loss: 0.0174 | Val Loss: 0.0225\n",
      "[2024-01-08 23:59:04,533] Epoch: 30 | Ph  | Train Loss: 0.160 | Val Loss: 0.192\n",
      "[2024-01-08 23:59:04,534] Epoch: 30 | Ending LR: 0.000054 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:28<00:00,  1.25s/it]\n",
      "[2024-01-09 00:03:35,113] Epoch: 31 | FT  | Train Loss: 0.17465 | Val Loss: 0.22239\n",
      "[2024-01-09 00:03:35,114] Epoch: 31 | Amp | Train Loss: 0.0170 | Val Loss: 0.0237\n",
      "[2024-01-09 00:03:35,115] Epoch: 31 | Ph  | Train Loss: 0.158 | Val Loss: 0.199\n",
      "[2024-01-09 00:03:35,115] Epoch: 31 | Ending LR: 0.000047 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:31<00:00,  1.26s/it]\n",
      "[2024-01-09 00:08:09,450] Saving improved model after Val Loss improved from 0.21346 to 0.21205\n",
      "[2024-01-09 00:08:09,570] Epoch: 32 | FT  | Train Loss: 0.17254 | Val Loss: 0.21205\n",
      "[2024-01-09 00:08:09,571] Epoch: 32 | Amp | Train Loss: 0.0171 | Val Loss: 0.0236\n",
      "[2024-01-09 00:08:09,572] Epoch: 32 | Ph  | Train Loss: 0.155 | Val Loss: 0.188\n",
      "[2024-01-09 00:08:09,573] Epoch: 32 | Ending LR: 0.000039 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:22<00:00,  1.22s/it]\n",
      "[2024-01-09 00:12:33,919] Epoch: 33 | FT  | Train Loss: 0.16886 | Val Loss: 0.21328\n",
      "[2024-01-09 00:12:33,921] Epoch: 33 | Amp | Train Loss: 0.0167 | Val Loss: 0.0226\n",
      "[2024-01-09 00:12:33,921] Epoch: 33 | Ph  | Train Loss: 0.152 | Val Loss: 0.191\n",
      "[2024-01-09 00:12:33,922] Epoch: 33 | Ending LR: 0.000031 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:16<00:00,  1.19s/it]\n",
      "[2024-01-09 00:16:52,724] Saving improved model after Val Loss improved from 0.21205 to 0.21077\n",
      "[2024-01-09 00:16:52,838] Epoch: 34 | FT  | Train Loss: 0.16597 | Val Loss: 0.21077\n",
      "[2024-01-09 00:16:52,839] Epoch: 34 | Amp | Train Loss: 0.0166 | Val Loss: 0.0222\n",
      "[2024-01-09 00:16:52,840] Epoch: 34 | Ph  | Train Loss: 0.149 | Val Loss: 0.189\n",
      "[2024-01-09 00:16:52,841] Epoch: 34 | Ending LR: 0.000024 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:13<00:00,  1.18s/it]\n",
      "[2024-01-09 00:21:08,474] Epoch: 35 | FT  | Train Loss: 0.16428 | Val Loss: 0.21224\n",
      "[2024-01-09 00:21:08,475] Epoch: 35 | Amp | Train Loss: 0.0165 | Val Loss: 0.0228\n",
      "[2024-01-09 00:21:08,476] Epoch: 35 | Ph  | Train Loss: 0.148 | Val Loss: 0.189\n",
      "[2024-01-09 00:21:08,477] Epoch: 35 | Ending LR: 0.000022 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:08<00:00,  1.16s/it]\n",
      "[2024-01-09 00:25:19,321] Saving improved model after Val Loss improved from 0.21077 to 0.20964\n",
      "[2024-01-09 00:25:19,462] Epoch: 36 | FT  | Train Loss: 0.16380 | Val Loss: 0.20964\n",
      "[2024-01-09 00:25:19,464] Epoch: 36 | Amp | Train Loss: 0.0164 | Val Loss: 0.0227\n",
      "[2024-01-09 00:25:19,465] Epoch: 36 | Ph  | Train Loss: 0.147 | Val Loss: 0.187\n",
      "[2024-01-09 00:25:19,466] Epoch: 36 | Ending LR: 0.000026 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:08<00:00,  1.16s/it]\n",
      "[2024-01-09 00:29:30,511] Epoch: 37 | FT  | Train Loss: 0.16374 | Val Loss: 0.22045\n",
      "[2024-01-09 00:29:30,512] Epoch: 37 | Amp | Train Loss: 0.0166 | Val Loss: 0.0239\n",
      "[2024-01-09 00:29:30,513] Epoch: 37 | Ph  | Train Loss: 0.147 | Val Loss: 0.197\n",
      "[2024-01-09 00:29:30,514] Epoch: 37 | Ending LR: 0.000030 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:05<00:00,  1.14s/it]\n",
      "[2024-01-09 00:33:38,573] Saving improved model after Val Loss improved from 0.20964 to 0.20911\n",
      "[2024-01-09 00:33:38,666] Epoch: 38 | FT  | Train Loss: 0.16452 | Val Loss: 0.20911\n",
      "[2024-01-09 00:33:38,668] Epoch: 38 | Amp | Train Loss: 0.0165 | Val Loss: 0.0222\n",
      "[2024-01-09 00:33:38,669] Epoch: 38 | Ph  | Train Loss: 0.148 | Val Loss: 0.187\n",
      "[2024-01-09 00:33:38,670] Epoch: 38 | Ending LR: 0.000033 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:06<00:00,  1.14s/it]\n",
      "[2024-01-09 00:37:46,947] Epoch: 39 | FT  | Train Loss: 0.16330 | Val Loss: 0.21065\n",
      "[2024-01-09 00:37:46,948] Epoch: 39 | Amp | Train Loss: 0.0163 | Val Loss: 0.0229\n",
      "[2024-01-09 00:37:46,949] Epoch: 39 | Ph  | Train Loss: 0.147 | Val Loss: 0.188\n",
      "[2024-01-09 00:37:46,950] Epoch: 39 | Ending LR: 0.000037 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:10<00:00,  1.16s/it]\n",
      "[2024-01-09 00:41:59,657] Epoch: 40 | FT  | Train Loss: 0.16353 | Val Loss: 0.21822\n",
      "[2024-01-09 00:41:59,660] Epoch: 40 | Amp | Train Loss: 0.0164 | Val Loss: 0.0219\n",
      "[2024-01-09 00:41:59,660] Epoch: 40 | Ph  | Train Loss: 0.147 | Val Loss: 0.196\n",
      "[2024-01-09 00:41:59,661] Epoch: 40 | Ending LR: 0.000041 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:11<00:00,  1.17s/it]\n",
      "[2024-01-09 00:46:13,747] Epoch: 41 | FT  | Train Loss: 0.16357 | Val Loss: 0.21066\n",
      "[2024-01-09 00:46:13,748] Epoch: 41 | Amp | Train Loss: 0.0163 | Val Loss: 0.0223\n",
      "[2024-01-09 00:46:13,749] Epoch: 41 | Ph  | Train Loss: 0.147 | Val Loss: 0.188\n",
      "[2024-01-09 00:46:13,749] Epoch: 41 | Ending LR: 0.000040 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:07<00:00,  1.15s/it]\n",
      "[2024-01-09 00:50:23,230] Epoch: 42 | FT  | Train Loss: 0.16103 | Val Loss: 0.20927\n",
      "[2024-01-09 00:50:23,232] Epoch: 42 | Amp | Train Loss: 0.0162 | Val Loss: 0.0218\n",
      "[2024-01-09 00:50:23,233] Epoch: 42 | Ph  | Train Loss: 0.145 | Val Loss: 0.187\n",
      "[2024-01-09 00:50:23,233] Epoch: 42 | Ending LR: 0.000036 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:05<00:00,  1.14s/it]\n",
      "[2024-01-09 00:54:30,971] Epoch: 43 | FT  | Train Loss: 0.15919 | Val Loss: 0.21030\n",
      "[2024-01-09 00:54:30,972] Epoch: 43 | Amp | Train Loss: 0.0161 | Val Loss: 0.0228\n",
      "[2024-01-09 00:54:30,973] Epoch: 43 | Ph  | Train Loss: 0.143 | Val Loss: 0.188\n",
      "[2024-01-09 00:54:30,973] Epoch: 43 | Ending LR: 0.000033 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:08<00:00,  1.15s/it]\n",
      "[2024-01-09 00:58:41,305] Epoch: 44 | FT  | Train Loss: 0.15735 | Val Loss: 0.21055\n",
      "[2024-01-09 00:58:41,306] Epoch: 44 | Amp | Train Loss: 0.0159 | Val Loss: 0.0218\n",
      "[2024-01-09 00:58:41,307] Epoch: 44 | Ph  | Train Loss: 0.141 | Val Loss: 0.189\n",
      "[2024-01-09 00:58:41,307] Epoch: 44 | Ending LR: 0.000029 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:05<00:00,  1.14s/it]\n",
      "[2024-01-09 01:02:48,836] Epoch: 45 | FT  | Train Loss: 0.15578 | Val Loss: 0.20973\n",
      "[2024-01-09 01:02:48,837] Epoch: 45 | Amp | Train Loss: 0.0157 | Val Loss: 0.0222\n",
      "[2024-01-09 01:02:48,837] Epoch: 45 | Ph  | Train Loss: 0.140 | Val Loss: 0.187\n",
      "[2024-01-09 01:02:48,838] Epoch: 45 | Ending LR: 0.000025 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:06<00:00,  1.15s/it]\n",
      "[2024-01-09 01:06:57,825] Saving improved model after Val Loss improved from 0.20911 to 0.20795\n",
      "[2024-01-09 01:06:57,889] Epoch: 46 | FT  | Train Loss: 0.15410 | Val Loss: 0.20795\n",
      "[2024-01-09 01:06:57,890] Epoch: 46 | Amp | Train Loss: 0.0158 | Val Loss: 0.0219\n",
      "[2024-01-09 01:06:57,891] Epoch: 46 | Ph  | Train Loss: 0.138 | Val Loss: 0.186\n",
      "[2024-01-09 01:06:57,891] Epoch: 46 | Ending LR: 0.000021 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:03<00:00,  1.13s/it]\n",
      "[2024-01-09 01:11:03,959] Epoch: 47 | FT  | Train Loss: 0.15288 | Val Loss: 0.20889\n",
      "[2024-01-09 01:11:03,960] Epoch: 47 | Amp | Train Loss: 0.0155 | Val Loss: 0.0230\n",
      "[2024-01-09 01:11:03,960] Epoch: 47 | Ph  | Train Loss: 0.137 | Val Loss: 0.186\n",
      "[2024-01-09 01:11:03,961] Epoch: 47 | Ending LR: 0.000021 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:08<00:00,  1.16s/it]\n",
      "[2024-01-09 01:15:14,519] Epoch: 48 | FT  | Train Loss: 0.15261 | Val Loss: 0.20830\n",
      "[2024-01-09 01:15:14,520] Epoch: 48 | Amp | Train Loss: 0.0155 | Val Loss: 0.0228\n",
      "[2024-01-09 01:15:14,521] Epoch: 48 | Ph  | Train Loss: 0.137 | Val Loss: 0.186\n",
      "[2024-01-09 01:15:14,521] Epoch: 48 | Ending LR: 0.000023 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:09<00:00,  1.16s/it]\n",
      "[2024-01-09 01:19:26,177] Saving improved model after Val Loss improved from 0.20795 to 0.20750\n",
      "[2024-01-09 01:19:26,292] Epoch: 49 | FT  | Train Loss: 0.15234 | Val Loss: 0.20750\n",
      "[2024-01-09 01:19:26,293] Epoch: 49 | Amp | Train Loss: 0.0155 | Val Loss: 0.0230\n",
      "[2024-01-09 01:19:26,294] Epoch: 49 | Ph  | Train Loss: 0.137 | Val Loss: 0.184\n",
      "[2024-01-09 01:19:26,294] Epoch: 49 | Ending LR: 0.000025 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:06<00:00,  1.15s/it]\n",
      "[2024-01-09 01:23:35,264] Saving improved model after Val Loss improved from 0.20750 to 0.20718\n",
      "[2024-01-09 01:23:35,368] Epoch: 50 | FT  | Train Loss: 0.15224 | Val Loss: 0.20718\n",
      "[2024-01-09 01:23:35,369] Epoch: 50 | Amp | Train Loss: 0.0155 | Val Loss: 0.0216\n",
      "[2024-01-09 01:23:35,370] Epoch: 50 | Ph  | Train Loss: 0.137 | Val Loss: 0.186\n",
      "[2024-01-09 01:23:35,370] Epoch: 50 | Ending LR: 0.000027 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:06<00:00,  1.15s/it]\n",
      "[2024-01-09 01:27:44,307] Saving improved model after Val Loss improved from 0.20718 to 0.20716\n",
      "[2024-01-09 01:27:44,413] Epoch: 51 | FT  | Train Loss: 0.15226 | Val Loss: 0.20716\n",
      "[2024-01-09 01:27:44,414] Epoch: 51 | Amp | Train Loss: 0.0155 | Val Loss: 0.0227\n",
      "[2024-01-09 01:27:44,414] Epoch: 51 | Ph  | Train Loss: 0.137 | Val Loss: 0.184\n",
      "[2024-01-09 01:27:44,415] Epoch: 51 | Ending LR: 0.000029 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:05<00:00,  1.14s/it]\n",
      "[2024-01-09 01:31:51,849] Epoch: 52 | FT  | Train Loss: 0.15138 | Val Loss: 0.21237\n",
      "[2024-01-09 01:31:51,851] Epoch: 52 | Amp | Train Loss: 0.0155 | Val Loss: 0.0225\n",
      "[2024-01-09 01:31:51,851] Epoch: 52 | Ph  | Train Loss: 0.136 | Val Loss: 0.190\n",
      "[2024-01-09 01:31:51,853] Epoch: 52 | Ending LR: 0.000031 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:08<00:00,  1.16s/it]\n",
      "[2024-01-09 01:36:03,038] Epoch: 53 | FT  | Train Loss: 0.15117 | Val Loss: 0.20722\n",
      "[2024-01-09 01:36:03,040] Epoch: 53 | Amp | Train Loss: 0.0153 | Val Loss: 0.0216\n",
      "[2024-01-09 01:36:03,041] Epoch: 53 | Ph  | Train Loss: 0.136 | Val Loss: 0.186\n",
      "[2024-01-09 01:36:03,041] Epoch: 53 | Ending LR: 0.000030 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:06<00:00,  1.15s/it]\n",
      "[2024-01-09 01:40:12,093] Epoch: 54 | FT  | Train Loss: 0.14961 | Val Loss: 0.21267\n",
      "[2024-01-09 01:40:12,095] Epoch: 54 | Amp | Train Loss: 0.0153 | Val Loss: 0.0240\n",
      "[2024-01-09 01:40:12,096] Epoch: 54 | Ph  | Train Loss: 0.134 | Val Loss: 0.189\n",
      "[2024-01-09 01:40:12,097] Epoch: 54 | Ending LR: 0.000028 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:06<00:00,  1.15s/it]\n",
      "[2024-01-09 01:44:21,019] Epoch: 55 | FT  | Train Loss: 0.14870 | Val Loss: 0.20876\n",
      "[2024-01-09 01:44:21,020] Epoch: 55 | Amp | Train Loss: 0.0153 | Val Loss: 0.0230\n",
      "[2024-01-09 01:44:21,021] Epoch: 55 | Ph  | Train Loss: 0.133 | Val Loss: 0.186\n",
      "[2024-01-09 01:44:21,021] Epoch: 55 | Ending LR: 0.000026 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:05<00:00,  1.14s/it]\n",
      "[2024-01-09 01:48:28,875] Epoch: 56 | FT  | Train Loss: 0.14732 | Val Loss: 0.20907\n",
      "[2024-01-09 01:48:28,876] Epoch: 56 | Amp | Train Loss: 0.0150 | Val Loss: 0.0220\n",
      "[2024-01-09 01:48:28,877] Epoch: 56 | Ph  | Train Loss: 0.132 | Val Loss: 0.187\n",
      "[2024-01-09 01:48:28,878] Epoch: 56 | Ending LR: 0.000024 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:07<00:00,  1.15s/it]\n",
      "[2024-01-09 01:52:38,744] Saving improved model after Val Loss improved from 0.20716 to 0.20647\n",
      "[2024-01-09 01:52:38,862] Epoch: 57 | FT  | Train Loss: 0.14637 | Val Loss: 0.20647\n",
      "[2024-01-09 01:52:38,864] Epoch: 57 | Amp | Train Loss: 0.0150 | Val Loss: 0.0216\n",
      "[2024-01-09 01:52:38,865] Epoch: 57 | Ph  | Train Loss: 0.131 | Val Loss: 0.185\n",
      "[2024-01-09 01:52:38,866] Epoch: 57 | Ending LR: 0.000022 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:06<00:00,  1.14s/it]\n",
      "[2024-01-09 01:56:47,067] Epoch: 58 | FT  | Train Loss: 0.14533 | Val Loss: 0.20696\n",
      "[2024-01-09 01:56:47,069] Epoch: 58 | Amp | Train Loss: 0.0148 | Val Loss: 0.0216\n",
      "[2024-01-09 01:56:47,069] Epoch: 58 | Ph  | Train Loss: 0.131 | Val Loss: 0.185\n",
      "[2024-01-09 01:56:47,070] Epoch: 58 | Ending LR: 0.000020 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 215/215 [04:06<00:00,  1.15s/it]\n",
      "[2024-01-09 02:00:55,963] Epoch: 59 | FT  | Train Loss: 0.14472 | Val Loss: 0.20757\n",
      "[2024-01-09 02:00:55,964] Epoch: 59 | Amp | Train Loss: 0.0149 | Val Loss: 0.0231\n",
      "[2024-01-09 02:00:55,965] Epoch: 59 | Ph  | Train Loss: 0.130 | Val Loss: 0.184\n",
      "[2024-01-09 02:00:55,965] Epoch: 59 | Ending LR: 0.000021 \n",
      "[2024-01-09 02:00:56,082] Decimating dataset to 0.7 of the original size...\n",
      "[2024-01-09 02:00:56,227] Using DataParallel with 2 devices.\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:34<00:00,  1.14s/it]\n",
      "[2024-01-09 02:04:32,854] Saving improved model after Val Loss improved from inf to 0.58778\n",
      "[2024-01-09 02:04:32,908] Epoch: 0 | FT  | Train Loss: 0.69269 | Val Loss: 0.58778\n",
      "[2024-01-09 02:04:32,909] Epoch: 0 | Amp | Train Loss: 0.1205 | Val Loss: 0.0283\n",
      "[2024-01-09 02:04:32,910] Epoch: 0 | Ph  | Train Loss: 0.572 | Val Loss: 0.560\n",
      "[2024-01-09 02:04:32,910] Epoch: 0 | Ending LR: 0.000050 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:35<00:00,  1.15s/it]\n",
      "[2024-01-09 02:08:10,010] Saving improved model after Val Loss improved from 0.58778 to 0.58467\n",
      "[2024-01-09 02:08:10,104] Epoch: 1 | FT  | Train Loss: 0.58288 | Val Loss: 0.58467\n",
      "[2024-01-09 02:08:10,105] Epoch: 1 | Amp | Train Loss: 0.0223 | Val Loss: 0.0260\n",
      "[2024-01-09 02:08:10,106] Epoch: 1 | Ph  | Train Loss: 0.561 | Val Loss: 0.559\n",
      "[2024-01-09 02:08:10,106] Epoch: 1 | Ending LR: 0.000081 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:41<00:00,  1.18s/it]\n",
      "[2024-01-09 02:11:53,008] Saving improved model after Val Loss improved from 0.58467 to 0.42245\n",
      "[2024-01-09 02:11:53,119] Epoch: 2 | FT  | Train Loss: 0.52225 | Val Loss: 0.42245\n",
      "[2024-01-09 02:11:53,121] Epoch: 2 | Amp | Train Loss: 0.0228 | Val Loss: 0.0203\n",
      "[2024-01-09 02:11:53,122] Epoch: 2 | Ph  | Train Loss: 0.499 | Val Loss: 0.402\n",
      "[2024-01-09 02:11:53,123] Epoch: 2 | Ending LR: 0.000111 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:36<00:00,  1.15s/it]\n",
      "[2024-01-09 02:15:31,033] Saving improved model after Val Loss improved from 0.42245 to 0.36129\n",
      "[2024-01-09 02:15:31,137] Epoch: 3 | FT  | Train Loss: 0.39400 | Val Loss: 0.36129\n",
      "[2024-01-09 02:15:31,139] Epoch: 3 | Amp | Train Loss: 0.0215 | Val Loss: 0.0199\n",
      "[2024-01-09 02:15:31,139] Epoch: 3 | Ph  | Train Loss: 0.373 | Val Loss: 0.341\n",
      "[2024-01-09 02:15:31,140] Epoch: 3 | Ending LR: 0.000141 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:35<00:00,  1.14s/it]\n",
      "[2024-01-09 02:19:08,187] Saving improved model after Val Loss improved from 0.36129 to 0.29677\n",
      "[2024-01-09 02:19:08,284] Epoch: 4 | FT  | Train Loss: 0.32917 | Val Loss: 0.29677\n",
      "[2024-01-09 02:19:08,285] Epoch: 4 | Amp | Train Loss: 0.0215 | Val Loss: 0.0208\n",
      "[2024-01-09 02:19:08,287] Epoch: 4 | Ph  | Train Loss: 0.308 | Val Loss: 0.276\n",
      "[2024-01-09 02:19:08,288] Epoch: 4 | Ending LR: 0.000172 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:35<00:00,  1.15s/it]\n",
      "[2024-01-09 02:22:45,569] Saving improved model after Val Loss improved from 0.29677 to 0.28233\n",
      "[2024-01-09 02:22:45,681] Epoch: 5 | FT  | Train Loss: 0.29307 | Val Loss: 0.28233\n",
      "[2024-01-09 02:22:45,682] Epoch: 5 | Amp | Train Loss: 0.0211 | Val Loss: 0.0189\n",
      "[2024-01-09 02:22:45,684] Epoch: 5 | Ph  | Train Loss: 0.272 | Val Loss: 0.263\n",
      "[2024-01-09 02:22:45,685] Epoch: 5 | Ending LR: 0.000198 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:37<00:00,  1.16s/it]\n",
      "[2024-01-09 02:26:25,019] Saving improved model after Val Loss improved from 0.28233 to 0.26865\n",
      "[2024-01-09 02:26:25,135] Epoch: 6 | FT  | Train Loss: 0.27044 | Val Loss: 0.26865\n",
      "[2024-01-09 02:26:25,137] Epoch: 6 | Amp | Train Loss: 0.0204 | Val Loss: 0.0203\n",
      "[2024-01-09 02:26:25,138] Epoch: 6 | Ph  | Train Loss: 0.250 | Val Loss: 0.248\n",
      "[2024-01-09 02:26:25,139] Epoch: 6 | Ending LR: 0.000168 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:36<00:00,  1.15s/it]\n",
      "[2024-01-09 02:30:03,834] Saving improved model after Val Loss improved from 0.26865 to 0.25315\n",
      "[2024-01-09 02:30:03,944] Epoch: 7 | FT  | Train Loss: 0.25280 | Val Loss: 0.25315\n",
      "[2024-01-09 02:30:03,945] Epoch: 7 | Amp | Train Loss: 0.0202 | Val Loss: 0.0227\n",
      "[2024-01-09 02:30:03,945] Epoch: 7 | Ph  | Train Loss: 0.233 | Val Loss: 0.230\n",
      "[2024-01-09 02:30:03,946] Epoch: 7 | Ending LR: 0.000137 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:35<00:00,  1.14s/it]\n",
      "[2024-01-09 02:33:40,892] Saving improved model after Val Loss improved from 0.25315 to 0.24003\n",
      "[2024-01-09 02:33:40,995] Epoch: 8 | FT  | Train Loss: 0.24243 | Val Loss: 0.24003\n",
      "[2024-01-09 02:33:40,997] Epoch: 8 | Amp | Train Loss: 0.0198 | Val Loss: 0.0185\n",
      "[2024-01-09 02:33:40,998] Epoch: 8 | Ph  | Train Loss: 0.223 | Val Loss: 0.222\n",
      "[2024-01-09 02:33:40,999] Epoch: 8 | Ending LR: 0.000107 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:36<00:00,  1.15s/it]\n",
      "[2024-01-09 02:37:19,371] Saving improved model after Val Loss improved from 0.24003 to 0.23993\n",
      "[2024-01-09 02:37:19,509] Epoch: 9 | FT  | Train Loss: 0.23279 | Val Loss: 0.23993\n",
      "[2024-01-09 02:37:19,511] Epoch: 9 | Amp | Train Loss: 0.0195 | Val Loss: 0.0197\n",
      "[2024-01-09 02:37:19,512] Epoch: 9 | Ph  | Train Loss: 0.213 | Val Loss: 0.220\n",
      "[2024-01-09 02:37:19,513] Epoch: 9 | Ending LR: 0.000077 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:35<00:00,  1.14s/it]\n",
      "[2024-01-09 02:40:56,523] Saving improved model after Val Loss improved from 0.23993 to 0.23401\n",
      "[2024-01-09 02:40:56,622] Epoch: 10 | FT  | Train Loss: 0.22600 | Val Loss: 0.23401\n",
      "[2024-01-09 02:40:56,623] Epoch: 10 | Amp | Train Loss: 0.0192 | Val Loss: 0.0194\n",
      "[2024-01-09 02:40:56,623] Epoch: 10 | Ph  | Train Loss: 0.207 | Val Loss: 0.215\n",
      "[2024-01-09 02:40:56,624] Epoch: 10 | Ending LR: 0.000046 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:37<00:00,  1.16s/it]\n",
      "[2024-01-09 02:44:35,963] Saving improved model after Val Loss improved from 0.23401 to 0.22541\n",
      "[2024-01-09 02:44:36,065] Epoch: 11 | FT  | Train Loss: 0.21976 | Val Loss: 0.22541\n",
      "[2024-01-09 02:44:36,066] Epoch: 11 | Amp | Train Loss: 0.0189 | Val Loss: 0.0184\n",
      "[2024-01-09 02:44:36,067] Epoch: 11 | Ph  | Train Loss: 0.201 | Val Loss: 0.207\n",
      "[2024-01-09 02:44:36,068] Epoch: 11 | Ending LR: 0.000022 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:35<00:00,  1.15s/it]\n",
      "[2024-01-09 02:48:13,702] Epoch: 12 | FT  | Train Loss: 0.21743 | Val Loss: 0.22892\n",
      "[2024-01-09 02:48:13,704] Epoch: 12 | Amp | Train Loss: 0.0189 | Val Loss: 0.0184\n",
      "[2024-01-09 02:48:13,704] Epoch: 12 | Ph  | Train Loss: 0.199 | Val Loss: 0.211\n",
      "[2024-01-09 02:48:13,705] Epoch: 12 | Ending LR: 0.000037 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:36<00:00,  1.15s/it]\n",
      "[2024-01-09 02:51:52,203] Epoch: 13 | FT  | Train Loss: 0.21745 | Val Loss: 0.23512\n",
      "[2024-01-09 02:51:52,204] Epoch: 13 | Amp | Train Loss: 0.0190 | Val Loss: 0.0195\n",
      "[2024-01-09 02:51:52,204] Epoch: 13 | Ph  | Train Loss: 0.198 | Val Loss: 0.216\n",
      "[2024-01-09 02:51:52,205] Epoch: 13 | Ending LR: 0.000052 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:36<00:00,  1.15s/it]\n",
      "[2024-01-09 02:55:30,946] Epoch: 14 | FT  | Train Loss: 0.21817 | Val Loss: 0.22837\n",
      "[2024-01-09 02:55:30,946] Epoch: 14 | Amp | Train Loss: 0.0191 | Val Loss: 0.0184\n",
      "[2024-01-09 02:55:30,947] Epoch: 14 | Ph  | Train Loss: 0.199 | Val Loss: 0.210\n",
      "[2024-01-09 02:55:30,947] Epoch: 14 | Ending LR: 0.000067 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:36<00:00,  1.15s/it]\n",
      "[2024-01-09 02:59:09,306] Epoch: 15 | FT  | Train Loss: 0.21715 | Val Loss: 0.22948\n",
      "[2024-01-09 02:59:09,307] Epoch: 15 | Amp | Train Loss: 0.0192 | Val Loss: 0.0186\n",
      "[2024-01-09 02:59:09,308] Epoch: 15 | Ph  | Train Loss: 0.198 | Val Loss: 0.211\n",
      "[2024-01-09 02:59:09,309] Epoch: 15 | Ending LR: 0.000083 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:33<00:00,  1.13s/it]\n",
      "[2024-01-09 03:02:44,101] Epoch: 16 | FT  | Train Loss: 0.21562 | Val Loss: 0.23347\n",
      "[2024-01-09 03:02:44,102] Epoch: 16 | Amp | Train Loss: 0.0192 | Val Loss: 0.0186\n",
      "[2024-01-09 03:02:44,103] Epoch: 16 | Ph  | Train Loss: 0.196 | Val Loss: 0.215\n",
      "[2024-01-09 03:02:44,104] Epoch: 16 | Ending LR: 0.000098 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:34<00:00,  1.14s/it]\n",
      "[2024-01-09 03:06:20,847] Epoch: 17 | FT  | Train Loss: 0.21497 | Val Loss: 0.23214\n",
      "[2024-01-09 03:06:20,848] Epoch: 17 | Amp | Train Loss: 0.0193 | Val Loss: 0.0215\n",
      "[2024-01-09 03:06:20,849] Epoch: 17 | Ph  | Train Loss: 0.196 | Val Loss: 0.211\n",
      "[2024-01-09 03:06:20,849] Epoch: 17 | Ending LR: 0.000107 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:33<00:00,  1.14s/it]\n",
      "[2024-01-09 03:09:56,189] Saving improved model after Val Loss improved from 0.22541 to 0.22154\n",
      "[2024-01-09 03:09:56,285] Epoch: 18 | FT  | Train Loss: 0.20953 | Val Loss: 0.22154\n",
      "[2024-01-09 03:09:56,287] Epoch: 18 | Amp | Train Loss: 0.0189 | Val Loss: 0.0200\n",
      "[2024-01-09 03:09:56,288] Epoch: 18 | Ph  | Train Loss: 0.191 | Val Loss: 0.202\n",
      "[2024-01-09 03:09:56,290] Epoch: 18 | Ending LR: 0.000092 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:37<00:00,  1.16s/it]\n",
      "[2024-01-09 03:13:35,857] Epoch: 19 | FT  | Train Loss: 0.20378 | Val Loss: 0.22618\n",
      "[2024-01-09 03:13:35,858] Epoch: 19 | Amp | Train Loss: 0.0187 | Val Loss: 0.0194\n",
      "[2024-01-09 03:13:35,859] Epoch: 19 | Ph  | Train Loss: 0.185 | Val Loss: 0.207\n",
      "[2024-01-09 03:13:35,860] Epoch: 19 | Ending LR: 0.000077 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:35<00:00,  1.15s/it]\n",
      "[2024-01-09 03:17:13,375] Saving improved model after Val Loss improved from 0.22154 to 0.21611\n",
      "[2024-01-09 03:17:13,488] Epoch: 20 | FT  | Train Loss: 0.19999 | Val Loss: 0.21611\n",
      "[2024-01-09 03:17:13,490] Epoch: 20 | Amp | Train Loss: 0.0189 | Val Loss: 0.0182\n",
      "[2024-01-09 03:17:13,491] Epoch: 20 | Ph  | Train Loss: 0.181 | Val Loss: 0.198\n",
      "[2024-01-09 03:17:13,492] Epoch: 20 | Ending LR: 0.000062 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:35<00:00,  1.14s/it]\n",
      "[2024-01-09 03:20:50,395] Saving improved model after Val Loss improved from 0.21611 to 0.21594\n",
      "[2024-01-09 03:20:50,488] Epoch: 21 | FT  | Train Loss: 0.19454 | Val Loss: 0.21594\n",
      "[2024-01-09 03:20:50,490] Epoch: 21 | Amp | Train Loss: 0.0183 | Val Loss: 0.0186\n",
      "[2024-01-09 03:20:50,491] Epoch: 21 | Ph  | Train Loss: 0.176 | Val Loss: 0.197\n",
      "[2024-01-09 03:20:50,492] Epoch: 21 | Ending LR: 0.000046 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:35<00:00,  1.15s/it]\n",
      "[2024-01-09 03:24:27,831] Saving improved model after Val Loss improved from 0.21594 to 0.20969\n",
      "[2024-01-09 03:24:27,934] Epoch: 22 | FT  | Train Loss: 0.19094 | Val Loss: 0.20969\n",
      "[2024-01-09 03:24:27,935] Epoch: 22 | Amp | Train Loss: 0.0181 | Val Loss: 0.0183\n",
      "[2024-01-09 03:24:27,936] Epoch: 22 | Ph  | Train Loss: 0.173 | Val Loss: 0.191\n",
      "[2024-01-09 03:24:27,937] Epoch: 22 | Ending LR: 0.000031 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:33<00:00,  1.14s/it]\n",
      "[2024-01-09 03:28:03,607] Saving improved model after Val Loss improved from 0.20969 to 0.20842\n",
      "[2024-01-09 03:28:03,704] Epoch: 23 | FT  | Train Loss: 0.18700 | Val Loss: 0.20842\n",
      "[2024-01-09 03:28:03,705] Epoch: 23 | Amp | Train Loss: 0.0180 | Val Loss: 0.0185\n",
      "[2024-01-09 03:28:03,705] Epoch: 23 | Ph  | Train Loss: 0.169 | Val Loss: 0.190\n",
      "[2024-01-09 03:28:03,706] Epoch: 23 | Ending LR: 0.000022 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:34<00:00,  1.14s/it]\n",
      "[2024-01-09 03:31:39,982] Epoch: 24 | FT  | Train Loss: 0.18569 | Val Loss: 0.20932\n",
      "[2024-01-09 03:31:39,983] Epoch: 24 | Amp | Train Loss: 0.0179 | Val Loss: 0.0185\n",
      "[2024-01-09 03:31:39,984] Epoch: 24 | Ph  | Train Loss: 0.168 | Val Loss: 0.191\n",
      "[2024-01-09 03:31:39,984] Epoch: 24 | Ending LR: 0.000030 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:35<00:00,  1.15s/it]\n",
      "[2024-01-09 03:35:17,090] Epoch: 25 | FT  | Train Loss: 0.18591 | Val Loss: 0.21411\n",
      "[2024-01-09 03:35:17,091] Epoch: 25 | Amp | Train Loss: 0.0179 | Val Loss: 0.0187\n",
      "[2024-01-09 03:35:17,091] Epoch: 25 | Ph  | Train Loss: 0.168 | Val Loss: 0.195\n",
      "[2024-01-09 03:35:17,092] Epoch: 25 | Ending LR: 0.000037 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:33<00:00,  1.14s/it]\n",
      "[2024-01-09 03:38:52,346] Epoch: 26 | FT  | Train Loss: 0.18653 | Val Loss: 0.21308\n",
      "[2024-01-09 03:38:52,347] Epoch: 26 | Amp | Train Loss: 0.0181 | Val Loss: 0.0194\n",
      "[2024-01-09 03:38:52,348] Epoch: 26 | Ph  | Train Loss: 0.168 | Val Loss: 0.194\n",
      "[2024-01-09 03:38:52,348] Epoch: 26 | Ending LR: 0.000045 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:34<00:00,  1.14s/it]\n",
      "[2024-01-09 03:42:28,945] Epoch: 27 | FT  | Train Loss: 0.18609 | Val Loss: 0.21134\n",
      "[2024-01-09 03:42:28,946] Epoch: 27 | Amp | Train Loss: 0.0180 | Val Loss: 0.0184\n",
      "[2024-01-09 03:42:28,947] Epoch: 27 | Ph  | Train Loss: 0.168 | Val Loss: 0.193\n",
      "[2024-01-09 03:42:28,947] Epoch: 27 | Ending LR: 0.000052 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:35<00:00,  1.14s/it]\n",
      "[2024-01-09 03:46:05,793] Epoch: 28 | FT  | Train Loss: 0.18659 | Val Loss: 0.22133\n",
      "[2024-01-09 03:46:05,794] Epoch: 28 | Amp | Train Loss: 0.0183 | Val Loss: 0.0184\n",
      "[2024-01-09 03:46:05,794] Epoch: 28 | Ph  | Train Loss: 0.168 | Val Loss: 0.203\n",
      "[2024-01-09 03:46:05,795] Epoch: 28 | Ending LR: 0.000060 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:37<00:00,  1.16s/it]\n",
      "[2024-01-09 03:49:44,736] Saving improved model after Val Loss improved from 0.20842 to 0.20831\n",
      "[2024-01-09 03:49:44,847] Epoch: 29 | FT  | Train Loss: 0.18531 | Val Loss: 0.20831\n",
      "[2024-01-09 03:49:44,848] Epoch: 29 | Amp | Train Loss: 0.0182 | Val Loss: 0.0179\n",
      "[2024-01-09 03:49:44,849] Epoch: 29 | Ph  | Train Loss: 0.167 | Val Loss: 0.190\n",
      "[2024-01-09 03:49:44,850] Epoch: 29 | Ending LR: 0.000063 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:37<00:00,  1.15s/it]\n",
      "[2024-01-09 03:53:23,701] Epoch: 30 | FT  | Train Loss: 0.18185 | Val Loss: 0.21240\n",
      "[2024-01-09 03:53:23,702] Epoch: 30 | Amp | Train Loss: 0.0178 | Val Loss: 0.0180\n",
      "[2024-01-09 03:53:23,705] Epoch: 30 | Ph  | Train Loss: 0.164 | Val Loss: 0.194\n",
      "[2024-01-09 03:53:23,706] Epoch: 30 | Ending LR: 0.000055 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:36<00:00,  1.15s/it]\n",
      "[2024-01-09 03:57:02,420] Saving improved model after Val Loss improved from 0.20831 to 0.20654\n",
      "[2024-01-09 03:57:02,517] Epoch: 31 | FT  | Train Loss: 0.17876 | Val Loss: 0.20654\n",
      "[2024-01-09 03:57:02,518] Epoch: 31 | Amp | Train Loss: 0.0176 | Val Loss: 0.0185\n",
      "[2024-01-09 03:57:02,519] Epoch: 31 | Ph  | Train Loss: 0.161 | Val Loss: 0.188\n",
      "[2024-01-09 03:57:02,520] Epoch: 31 | Ending LR: 0.000047 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:36<00:00,  1.15s/it]\n",
      "[2024-01-09 04:00:40,368] Saving improved model after Val Loss improved from 0.20654 to 0.20441\n",
      "[2024-01-09 04:00:40,479] Epoch: 32 | FT  | Train Loss: 0.17574 | Val Loss: 0.20441\n",
      "[2024-01-09 04:00:40,480] Epoch: 32 | Amp | Train Loss: 0.0174 | Val Loss: 0.0178\n",
      "[2024-01-09 04:00:40,481] Epoch: 32 | Ph  | Train Loss: 0.158 | Val Loss: 0.187\n",
      "[2024-01-09 04:00:40,481] Epoch: 32 | Ending LR: 0.000040 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:35<00:00,  1.14s/it]\n",
      "[2024-01-09 04:04:17,291] Epoch: 33 | FT  | Train Loss: 0.17316 | Val Loss: 0.20451\n",
      "[2024-01-09 04:04:17,292] Epoch: 33 | Amp | Train Loss: 0.0175 | Val Loss: 0.0186\n",
      "[2024-01-09 04:04:17,292] Epoch: 33 | Ph  | Train Loss: 0.156 | Val Loss: 0.186\n",
      "[2024-01-09 04:04:17,293] Epoch: 33 | Ending LR: 0.000032 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:35<00:00,  1.15s/it]\n",
      "[2024-01-09 04:07:54,575] Epoch: 34 | FT  | Train Loss: 0.17082 | Val Loss: 0.20568\n",
      "[2024-01-09 04:07:54,576] Epoch: 34 | Amp | Train Loss: 0.0172 | Val Loss: 0.0181\n",
      "[2024-01-09 04:07:54,576] Epoch: 34 | Ph  | Train Loss: 0.154 | Val Loss: 0.188\n",
      "[2024-01-09 04:07:54,577] Epoch: 34 | Ending LR: 0.000025 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:37<00:00,  1.16s/it]\n",
      "[2024-01-09 04:11:33,674] Saving improved model after Val Loss improved from 0.20441 to 0.20267\n",
      "[2024-01-09 04:11:33,766] Epoch: 35 | FT  | Train Loss: 0.16832 | Val Loss: 0.20267\n",
      "[2024-01-09 04:11:33,767] Epoch: 35 | Amp | Train Loss: 0.0171 | Val Loss: 0.0179\n",
      "[2024-01-09 04:11:33,768] Epoch: 35 | Ph  | Train Loss: 0.151 | Val Loss: 0.185\n",
      "[2024-01-09 04:11:33,768] Epoch: 35 | Ending LR: 0.000021 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:37<00:00,  1.16s/it]\n",
      "[2024-01-09 04:15:13,455] Saving improved model after Val Loss improved from 0.20267 to 0.20262\n",
      "[2024-01-09 04:15:13,566] Epoch: 36 | FT  | Train Loss: 0.16783 | Val Loss: 0.20262\n",
      "[2024-01-09 04:15:13,568] Epoch: 36 | Amp | Train Loss: 0.0171 | Val Loss: 0.0177\n",
      "[2024-01-09 04:15:13,569] Epoch: 36 | Ph  | Train Loss: 0.151 | Val Loss: 0.185\n",
      "[2024-01-09 04:15:13,570] Epoch: 36 | Ending LR: 0.000025 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:39<00:00,  1.17s/it]\n",
      "[2024-01-09 04:18:55,075] Epoch: 37 | FT  | Train Loss: 0.16790 | Val Loss: 0.20275\n",
      "[2024-01-09 04:18:55,076] Epoch: 37 | Amp | Train Loss: 0.0171 | Val Loss: 0.0178\n",
      "[2024-01-09 04:18:55,077] Epoch: 37 | Ph  | Train Loss: 0.151 | Val Loss: 0.185\n",
      "[2024-01-09 04:18:55,077] Epoch: 37 | Ending LR: 0.000029 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:39<00:00,  1.17s/it]\n",
      "[2024-01-09 04:22:36,020] Saving improved model after Val Loss improved from 0.20262 to 0.20185\n",
      "[2024-01-09 04:22:36,141] Epoch: 38 | FT  | Train Loss: 0.16801 | Val Loss: 0.20185\n",
      "[2024-01-09 04:22:36,143] Epoch: 38 | Amp | Train Loss: 0.0171 | Val Loss: 0.0181\n",
      "[2024-01-09 04:22:36,144] Epoch: 38 | Ph  | Train Loss: 0.151 | Val Loss: 0.184\n",
      "[2024-01-09 04:22:36,145] Epoch: 38 | Ending LR: 0.000033 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:35<00:00,  1.14s/it]\n",
      "[2024-01-09 04:26:13,093] Epoch: 39 | FT  | Train Loss: 0.16799 | Val Loss: 0.20271\n",
      "[2024-01-09 04:26:13,094] Epoch: 39 | Amp | Train Loss: 0.0170 | Val Loss: 0.0177\n",
      "[2024-01-09 04:26:13,095] Epoch: 39 | Ph  | Train Loss: 0.151 | Val Loss: 0.185\n",
      "[2024-01-09 04:26:13,095] Epoch: 39 | Ending LR: 0.000037 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:35<00:00,  1.15s/it]\n",
      "[2024-01-09 04:29:50,686] Epoch: 40 | FT  | Train Loss: 0.16792 | Val Loss: 0.20704\n",
      "[2024-01-09 04:29:50,687] Epoch: 40 | Amp | Train Loss: 0.0174 | Val Loss: 0.0205\n",
      "[2024-01-09 04:29:50,688] Epoch: 40 | Ph  | Train Loss: 0.151 | Val Loss: 0.186\n",
      "[2024-01-09 04:29:50,688] Epoch: 40 | Ending LR: 0.000040 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:36<00:00,  1.15s/it]\n",
      "[2024-01-09 04:33:28,754] Epoch: 41 | FT  | Train Loss: 0.16713 | Val Loss: 0.20253\n",
      "[2024-01-09 04:33:28,755] Epoch: 41 | Amp | Train Loss: 0.0170 | Val Loss: 0.0181\n",
      "[2024-01-09 04:33:28,755] Epoch: 41 | Ph  | Train Loss: 0.150 | Val Loss: 0.184\n",
      "[2024-01-09 04:33:28,756] Epoch: 41 | Ending LR: 0.000041 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:36<00:00,  1.15s/it]\n",
      "[2024-01-09 04:37:07,414] Epoch: 42 | FT  | Train Loss: 0.16476 | Val Loss: 0.20292\n",
      "[2024-01-09 04:37:07,415] Epoch: 42 | Amp | Train Loss: 0.0168 | Val Loss: 0.0176\n",
      "[2024-01-09 04:37:07,416] Epoch: 42 | Ph  | Train Loss: 0.148 | Val Loss: 0.185\n",
      "[2024-01-09 04:37:07,416] Epoch: 42 | Ending LR: 0.000037 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:34<00:00,  1.14s/it]\n",
      "[2024-01-09 04:40:44,135] Saving improved model after Val Loss improved from 0.20185 to 0.20180\n",
      "[2024-01-09 04:40:44,245] Epoch: 43 | FT  | Train Loss: 0.16344 | Val Loss: 0.20180\n",
      "[2024-01-09 04:40:44,247] Epoch: 43 | Amp | Train Loss: 0.0168 | Val Loss: 0.0178\n",
      "[2024-01-09 04:40:44,248] Epoch: 43 | Ph  | Train Loss: 0.147 | Val Loss: 0.184\n",
      "[2024-01-09 04:40:44,249] Epoch: 43 | Ending LR: 0.000033 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:34<00:00,  1.14s/it]\n",
      "[2024-01-09 04:44:20,121] Epoch: 44 | FT  | Train Loss: 0.16120 | Val Loss: 0.20228\n",
      "[2024-01-09 04:44:20,122] Epoch: 44 | Amp | Train Loss: 0.0166 | Val Loss: 0.0176\n",
      "[2024-01-09 04:44:20,123] Epoch: 44 | Ph  | Train Loss: 0.145 | Val Loss: 0.185\n",
      "[2024-01-09 04:44:20,123] Epoch: 44 | Ending LR: 0.000029 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:36<00:00,  1.15s/it]\n",
      "[2024-01-09 04:47:58,479] Saving improved model after Val Loss improved from 0.20180 to 0.20055\n",
      "[2024-01-09 04:47:58,595] Epoch: 45 | FT  | Train Loss: 0.15943 | Val Loss: 0.20055\n",
      "[2024-01-09 04:47:58,596] Epoch: 45 | Amp | Train Loss: 0.0165 | Val Loss: 0.0182\n",
      "[2024-01-09 04:47:58,597] Epoch: 45 | Ph  | Train Loss: 0.143 | Val Loss: 0.182\n",
      "[2024-01-09 04:47:58,598] Epoch: 45 | Ending LR: 0.000026 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:35<00:00,  1.15s/it]\n",
      "[2024-01-09 04:51:36,190] Saving improved model after Val Loss improved from 0.20055 to 0.20019\n",
      "[2024-01-09 04:51:36,294] Epoch: 46 | FT  | Train Loss: 0.15785 | Val Loss: 0.20019\n",
      "[2024-01-09 04:51:36,295] Epoch: 46 | Amp | Train Loss: 0.0164 | Val Loss: 0.0176\n",
      "[2024-01-09 04:51:36,296] Epoch: 46 | Ph  | Train Loss: 0.141 | Val Loss: 0.183\n",
      "[2024-01-09 04:51:36,297] Epoch: 46 | Ending LR: 0.000022 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:34<00:00,  1.14s/it]\n",
      "[2024-01-09 04:55:12,766] Epoch: 47 | FT  | Train Loss: 0.15668 | Val Loss: 0.20032\n",
      "[2024-01-09 04:55:12,767] Epoch: 47 | Amp | Train Loss: 0.0163 | Val Loss: 0.0176\n",
      "[2024-01-09 04:55:12,768] Epoch: 47 | Ph  | Train Loss: 0.140 | Val Loss: 0.183\n",
      "[2024-01-09 04:55:12,769] Epoch: 47 | Ending LR: 0.000021 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:35<00:00,  1.15s/it]\n",
      "[2024-01-09 04:58:49,912] Epoch: 48 | FT  | Train Loss: 0.15636 | Val Loss: 0.20156\n",
      "[2024-01-09 04:58:49,913] Epoch: 48 | Amp | Train Loss: 0.0163 | Val Loss: 0.0176\n",
      "[2024-01-09 04:58:49,913] Epoch: 48 | Ph  | Train Loss: 0.140 | Val Loss: 0.184\n",
      "[2024-01-09 04:58:49,914] Epoch: 48 | Ending LR: 0.000023 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:36<00:00,  1.15s/it]\n",
      "[2024-01-09 05:02:28,605] Saving improved model after Val Loss improved from 0.20019 to 0.19974\n",
      "[2024-01-09 05:02:28,710] Epoch: 49 | FT  | Train Loss: 0.15629 | Val Loss: 0.19974\n",
      "[2024-01-09 05:02:28,711] Epoch: 49 | Amp | Train Loss: 0.0162 | Val Loss: 0.0174\n",
      "[2024-01-09 05:02:28,712] Epoch: 49 | Ph  | Train Loss: 0.140 | Val Loss: 0.182\n",
      "[2024-01-09 05:02:28,713] Epoch: 49 | Ending LR: 0.000025 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:35<00:00,  1.15s/it]\n",
      "[2024-01-09 05:06:05,805] Epoch: 50 | FT  | Train Loss: 0.15580 | Val Loss: 0.20216\n",
      "[2024-01-09 05:06:05,806] Epoch: 50 | Amp | Train Loss: 0.0162 | Val Loss: 0.0178\n",
      "[2024-01-09 05:06:05,806] Epoch: 50 | Ph  | Train Loss: 0.140 | Val Loss: 0.184\n",
      "[2024-01-09 05:06:05,807] Epoch: 50 | Ending LR: 0.000027 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:37<00:00,  1.16s/it]\n",
      "[2024-01-09 05:09:44,984] Epoch: 51 | FT  | Train Loss: 0.15566 | Val Loss: 0.20246\n",
      "[2024-01-09 05:09:44,985] Epoch: 51 | Amp | Train Loss: 0.0163 | Val Loss: 0.0205\n",
      "[2024-01-09 05:09:44,986] Epoch: 51 | Ph  | Train Loss: 0.139 | Val Loss: 0.182\n",
      "[2024-01-09 05:09:44,986] Epoch: 51 | Ending LR: 0.000029 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:35<00:00,  1.15s/it]\n",
      "[2024-01-09 05:13:22,364] Epoch: 52 | FT  | Train Loss: 0.15560 | Val Loss: 0.20511\n",
      "[2024-01-09 05:13:22,366] Epoch: 52 | Amp | Train Loss: 0.0162 | Val Loss: 0.0196\n",
      "[2024-01-09 05:13:22,367] Epoch: 52 | Ph  | Train Loss: 0.139 | Val Loss: 0.185\n",
      "[2024-01-09 05:13:22,368] Epoch: 52 | Ending LR: 0.000030 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:34<00:00,  1.14s/it]\n",
      "[2024-01-09 05:16:59,093] Epoch: 53 | FT  | Train Loss: 0.15498 | Val Loss: 0.20005\n",
      "[2024-01-09 05:16:59,094] Epoch: 53 | Amp | Train Loss: 0.0161 | Val Loss: 0.0176\n",
      "[2024-01-09 05:16:59,095] Epoch: 53 | Ph  | Train Loss: 0.139 | Val Loss: 0.182\n",
      "[2024-01-09 05:16:59,095] Epoch: 53 | Ending LR: 0.000030 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:36<00:00,  1.15s/it]\n",
      "[2024-01-09 05:20:37,816] Epoch: 54 | FT  | Train Loss: 0.15315 | Val Loss: 0.20118\n",
      "[2024-01-09 05:20:37,818] Epoch: 54 | Amp | Train Loss: 0.0160 | Val Loss: 0.0178\n",
      "[2024-01-09 05:20:37,819] Epoch: 54 | Ph  | Train Loss: 0.137 | Val Loss: 0.183\n",
      "[2024-01-09 05:20:37,820] Epoch: 54 | Ending LR: 0.000028 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:37<00:00,  1.16s/it]\n",
      "[2024-01-09 05:24:16,904] Epoch: 55 | FT  | Train Loss: 0.15208 | Val Loss: 0.19995\n",
      "[2024-01-09 05:24:16,905] Epoch: 55 | Amp | Train Loss: 0.0159 | Val Loss: 0.0177\n",
      "[2024-01-09 05:24:16,906] Epoch: 55 | Ph  | Train Loss: 0.136 | Val Loss: 0.182\n",
      "[2024-01-09 05:24:16,906] Epoch: 55 | Ending LR: 0.000026 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:37<00:00,  1.16s/it]\n",
      "[2024-01-09 05:27:56,134] Epoch: 56 | FT  | Train Loss: 0.15130 | Val Loss: 0.20197\n",
      "[2024-01-09 05:27:56,135] Epoch: 56 | Amp | Train Loss: 0.0160 | Val Loss: 0.0175\n",
      "[2024-01-09 05:27:56,135] Epoch: 56 | Ph  | Train Loss: 0.135 | Val Loss: 0.184\n",
      "[2024-01-09 05:27:56,136] Epoch: 56 | Ending LR: 0.000024 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:36<00:00,  1.15s/it]\n",
      "[2024-01-09 05:31:34,106] Saving improved model after Val Loss improved from 0.19974 to 0.19871\n",
      "[2024-01-09 05:31:34,206] Epoch: 57 | FT  | Train Loss: 0.15023 | Val Loss: 0.19871\n",
      "[2024-01-09 05:31:34,208] Epoch: 57 | Amp | Train Loss: 0.0158 | Val Loss: 0.0174\n",
      "[2024-01-09 05:31:34,210] Epoch: 57 | Ph  | Train Loss: 0.134 | Val Loss: 0.181\n",
      "[2024-01-09 05:31:34,211] Epoch: 57 | Ending LR: 0.000023 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:36<00:00,  1.15s/it]\n",
      "[2024-01-09 05:35:12,698] Epoch: 58 | FT  | Train Loss: 0.14901 | Val Loss: 0.19950\n",
      "[2024-01-09 05:35:12,699] Epoch: 58 | Amp | Train Loss: 0.0156 | Val Loss: 0.0178\n",
      "[2024-01-09 05:35:12,700] Epoch: 58 | Ph  | Train Loss: 0.133 | Val Loss: 0.182\n",
      "[2024-01-09 05:35:12,700] Epoch: 58 | Ending LR: 0.000021 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 188/188 [03:35<00:00,  1.15s/it]\n",
      "[2024-01-09 05:38:49,975] Epoch: 59 | FT  | Train Loss: 0.14813 | Val Loss: 0.19980\n",
      "[2024-01-09 05:38:49,976] Epoch: 59 | Amp | Train Loss: 0.0156 | Val Loss: 0.0174\n",
      "[2024-01-09 05:38:49,977] Epoch: 59 | Ph  | Train Loss: 0.133 | Val Loss: 0.182\n",
      "[2024-01-09 05:38:49,978] Epoch: 59 | Ending LR: 0.000021 \n",
      "[2024-01-09 05:38:50,061] Decimating dataset to 0.6 of the original size...\n",
      "[2024-01-09 05:38:50,203] Using DataParallel with 2 devices.\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:04<00:00,  1.14s/it]\n",
      "[2024-01-09 05:41:56,046] Saving improved model after Val Loss improved from inf to 0.65582\n",
      "[2024-01-09 05:41:56,102] Epoch: 0 | FT  | Train Loss: 0.70613 | Val Loss: 0.65582\n",
      "[2024-01-09 05:41:56,103] Epoch: 0 | Amp | Train Loss: 0.1236 | Val Loss: 0.0721\n",
      "[2024-01-09 05:41:56,104] Epoch: 0 | Ph  | Train Loss: 0.583 | Val Loss: 0.584\n",
      "[2024-01-09 05:41:56,105] Epoch: 0 | Ending LR: 0.000050 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:03<00:00,  1.14s/it]\n",
      "[2024-01-09 05:45:01,459] Saving improved model after Val Loss improved from 0.65582 to 0.60377\n",
      "[2024-01-09 05:45:01,565] Epoch: 1 | FT  | Train Loss: 0.61193 | Val Loss: 0.60377\n",
      "[2024-01-09 05:45:01,566] Epoch: 1 | Amp | Train Loss: 0.0448 | Val Loss: 0.0244\n",
      "[2024-01-09 05:45:01,566] Epoch: 1 | Ph  | Train Loss: 0.567 | Val Loss: 0.579\n",
      "[2024-01-09 05:45:01,566] Epoch: 1 | Ending LR: 0.000081 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:04<00:00,  1.14s/it]\n",
      "[2024-01-09 05:48:07,144] Saving improved model after Val Loss improved from 0.60377 to 0.59612\n",
      "[2024-01-09 05:48:07,247] Epoch: 2 | FT  | Train Loss: 0.58129 | Val Loss: 0.59612\n",
      "[2024-01-09 05:48:07,249] Epoch: 2 | Amp | Train Loss: 0.0232 | Val Loss: 0.0274\n",
      "[2024-01-09 05:48:07,249] Epoch: 2 | Ph  | Train Loss: 0.558 | Val Loss: 0.569\n",
      "[2024-01-09 05:48:07,250] Epoch: 2 | Ending LR: 0.000111 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:04<00:00,  1.14s/it]\n",
      "[2024-01-09 05:51:12,888] Saving improved model after Val Loss improved from 0.59612 to 0.46592\n",
      "[2024-01-09 05:51:12,991] Epoch: 3 | FT  | Train Loss: 0.54112 | Val Loss: 0.46592\n",
      "[2024-01-09 05:51:12,991] Epoch: 3 | Amp | Train Loss: 0.0230 | Val Loss: 0.0264\n",
      "[2024-01-09 05:51:12,992] Epoch: 3 | Ph  | Train Loss: 0.518 | Val Loss: 0.440\n",
      "[2024-01-09 05:51:12,992] Epoch: 3 | Ending LR: 0.000142 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:05<00:00,  1.15s/it]\n",
      "[2024-01-09 05:54:20,464] Saving improved model after Val Loss improved from 0.46592 to 0.37321\n",
      "[2024-01-09 05:54:20,562] Epoch: 4 | FT  | Train Loss: 0.40653 | Val Loss: 0.37321\n",
      "[2024-01-09 05:54:20,563] Epoch: 4 | Amp | Train Loss: 0.0222 | Val Loss: 0.0189\n",
      "[2024-01-09 05:54:20,564] Epoch: 4 | Ph  | Train Loss: 0.384 | Val Loss: 0.354\n",
      "[2024-01-09 05:54:20,565] Epoch: 4 | Ending LR: 0.000172 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:04<00:00,  1.15s/it]\n",
      "[2024-01-09 05:57:26,607] Saving improved model after Val Loss improved from 0.37321 to 0.32045\n",
      "[2024-01-09 05:57:26,716] Epoch: 5 | FT  | Train Loss: 0.33517 | Val Loss: 0.32045\n",
      "[2024-01-09 05:57:26,717] Epoch: 5 | Amp | Train Loss: 0.0209 | Val Loss: 0.0193\n",
      "[2024-01-09 05:57:26,718] Epoch: 5 | Ph  | Train Loss: 0.314 | Val Loss: 0.301\n",
      "[2024-01-09 05:57:26,720] Epoch: 5 | Ending LR: 0.000198 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:05<00:00,  1.15s/it]\n",
      "[2024-01-09 06:00:33,993] Saving improved model after Val Loss improved from 0.32045 to 0.27926\n",
      "[2024-01-09 06:00:34,103] Epoch: 6 | FT  | Train Loss: 0.29150 | Val Loss: 0.27926\n",
      "[2024-01-09 06:00:34,105] Epoch: 6 | Amp | Train Loss: 0.0204 | Val Loss: 0.0197\n",
      "[2024-01-09 06:00:34,106] Epoch: 6 | Ph  | Train Loss: 0.271 | Val Loss: 0.260\n",
      "[2024-01-09 06:00:34,107] Epoch: 6 | Ending LR: 0.000167 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:04<00:00,  1.15s/it]\n",
      "[2024-01-09 06:03:40,539] Saving improved model after Val Loss improved from 0.27926 to 0.26773\n",
      "[2024-01-09 06:03:40,644] Epoch: 7 | FT  | Train Loss: 0.27012 | Val Loss: 0.26773\n",
      "[2024-01-09 06:03:40,645] Epoch: 7 | Amp | Train Loss: 0.0203 | Val Loss: 0.0196\n",
      "[2024-01-09 06:03:40,646] Epoch: 7 | Ph  | Train Loss: 0.250 | Val Loss: 0.248\n",
      "[2024-01-09 06:03:40,646] Epoch: 7 | Ending LR: 0.000137 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:05<00:00,  1.15s/it]\n",
      "[2024-01-09 06:06:48,093] Saving improved model after Val Loss improved from 0.26773 to 0.26148\n",
      "[2024-01-09 06:06:48,204] Epoch: 8 | FT  | Train Loss: 0.25426 | Val Loss: 0.26148\n",
      "[2024-01-09 06:06:48,206] Epoch: 8 | Amp | Train Loss: 0.0195 | Val Loss: 0.0185\n",
      "[2024-01-09 06:06:48,207] Epoch: 8 | Ph  | Train Loss: 0.235 | Val Loss: 0.243\n",
      "[2024-01-09 06:06:48,208] Epoch: 8 | Ending LR: 0.000107 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:05<00:00,  1.15s/it]\n",
      "[2024-01-09 06:09:55,181] Saving improved model after Val Loss improved from 0.26148 to 0.24926\n",
      "[2024-01-09 06:09:55,326] Epoch: 9 | FT  | Train Loss: 0.24507 | Val Loss: 0.24926\n",
      "[2024-01-09 06:09:55,327] Epoch: 9 | Amp | Train Loss: 0.0193 | Val Loss: 0.0180\n",
      "[2024-01-09 06:09:55,328] Epoch: 9 | Ph  | Train Loss: 0.226 | Val Loss: 0.231\n",
      "[2024-01-09 06:09:55,329] Epoch: 9 | Ending LR: 0.000076 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:05<00:00,  1.15s/it]\n",
      "[2024-01-09 06:13:02,663] Saving improved model after Val Loss improved from 0.24926 to 0.23941\n",
      "[2024-01-09 06:13:02,771] Epoch: 10 | FT  | Train Loss: 0.23641 | Val Loss: 0.23941\n",
      "[2024-01-09 06:13:02,772] Epoch: 10 | Amp | Train Loss: 0.0190 | Val Loss: 0.0179\n",
      "[2024-01-09 06:13:02,773] Epoch: 10 | Ph  | Train Loss: 0.217 | Val Loss: 0.221\n",
      "[2024-01-09 06:13:02,774] Epoch: 10 | Ending LR: 0.000046 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:06<00:00,  1.16s/it]\n",
      "[2024-01-09 06:16:10,714] Saving improved model after Val Loss improved from 0.23941 to 0.23598\n",
      "[2024-01-09 06:16:10,817] Epoch: 11 | FT  | Train Loss: 0.23011 | Val Loss: 0.23598\n",
      "[2024-01-09 06:16:10,818] Epoch: 11 | Amp | Train Loss: 0.0189 | Val Loss: 0.0182\n",
      "[2024-01-09 06:16:10,819] Epoch: 11 | Ph  | Train Loss: 0.211 | Val Loss: 0.218\n",
      "[2024-01-09 06:16:10,819] Epoch: 11 | Ending LR: 0.000022 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:05<00:00,  1.15s/it]\n",
      "[2024-01-09 06:19:17,615] Epoch: 12 | FT  | Train Loss: 0.22779 | Val Loss: 0.23720\n",
      "[2024-01-09 06:19:17,616] Epoch: 12 | Amp | Train Loss: 0.0187 | Val Loss: 0.0179\n",
      "[2024-01-09 06:19:17,616] Epoch: 12 | Ph  | Train Loss: 0.209 | Val Loss: 0.219\n",
      "[2024-01-09 06:19:17,617] Epoch: 12 | Ending LR: 0.000037 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:05<00:00,  1.16s/it]\n",
      "[2024-01-09 06:22:25,091] Saving improved model after Val Loss improved from 0.23598 to 0.23436\n",
      "[2024-01-09 06:22:25,222] Epoch: 13 | FT  | Train Loss: 0.22776 | Val Loss: 0.23436\n",
      "[2024-01-09 06:22:25,224] Epoch: 13 | Amp | Train Loss: 0.0189 | Val Loss: 0.0181\n",
      "[2024-01-09 06:22:25,225] Epoch: 13 | Ph  | Train Loss: 0.209 | Val Loss: 0.216\n",
      "[2024-01-09 06:22:25,226] Epoch: 13 | Ending LR: 0.000053 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:04<00:00,  1.15s/it]\n",
      "[2024-01-09 06:25:31,344] Epoch: 14 | FT  | Train Loss: 0.22670 | Val Loss: 0.23620\n",
      "[2024-01-09 06:25:31,345] Epoch: 14 | Amp | Train Loss: 0.0189 | Val Loss: 0.0180\n",
      "[2024-01-09 06:25:31,346] Epoch: 14 | Ph  | Train Loss: 0.208 | Val Loss: 0.218\n",
      "[2024-01-09 06:25:31,346] Epoch: 14 | Ending LR: 0.000068 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:04<00:00,  1.15s/it]\n",
      "[2024-01-09 06:28:37,447] Epoch: 15 | FT  | Train Loss: 0.22631 | Val Loss: 0.23702\n",
      "[2024-01-09 06:28:37,449] Epoch: 15 | Amp | Train Loss: 0.0190 | Val Loss: 0.0190\n",
      "[2024-01-09 06:28:37,449] Epoch: 15 | Ph  | Train Loss: 0.207 | Val Loss: 0.218\n",
      "[2024-01-09 06:28:37,450] Epoch: 15 | Ending LR: 0.000083 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:03<00:00,  1.14s/it]\n",
      "[2024-01-09 06:31:42,655] Saving improved model after Val Loss improved from 0.23436 to 0.23180\n",
      "[2024-01-09 06:31:42,758] Epoch: 16 | FT  | Train Loss: 0.22405 | Val Loss: 0.23180\n",
      "[2024-01-09 06:31:42,759] Epoch: 16 | Amp | Train Loss: 0.0192 | Val Loss: 0.0189\n",
      "[2024-01-09 06:31:42,760] Epoch: 16 | Ph  | Train Loss: 0.205 | Val Loss: 0.213\n",
      "[2024-01-09 06:31:42,760] Epoch: 16 | Ending LR: 0.000098 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:03<00:00,  1.14s/it]\n",
      "[2024-01-09 06:34:47,952] Saving improved model after Val Loss improved from 0.23180 to 0.22927\n",
      "[2024-01-09 06:34:48,070] Epoch: 17 | FT  | Train Loss: 0.22291 | Val Loss: 0.22927\n",
      "[2024-01-09 06:34:48,071] Epoch: 17 | Amp | Train Loss: 0.0192 | Val Loss: 0.0190\n",
      "[2024-01-09 06:34:48,071] Epoch: 17 | Ph  | Train Loss: 0.204 | Val Loss: 0.210\n",
      "[2024-01-09 06:34:48,072] Epoch: 17 | Ending LR: 0.000107 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:05<00:00,  1.15s/it]\n",
      "[2024-01-09 06:37:55,606] Saving improved model after Val Loss improved from 0.22927 to 0.22559\n",
      "[2024-01-09 06:37:55,714] Epoch: 18 | FT  | Train Loss: 0.21699 | Val Loss: 0.22559\n",
      "[2024-01-09 06:37:55,717] Epoch: 18 | Amp | Train Loss: 0.0191 | Val Loss: 0.0178\n",
      "[2024-01-09 06:37:55,718] Epoch: 18 | Ph  | Train Loss: 0.198 | Val Loss: 0.208\n",
      "[2024-01-09 06:37:55,719] Epoch: 18 | Ending LR: 0.000091 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:05<00:00,  1.15s/it]\n",
      "[2024-01-09 06:41:02,945] Saving improved model after Val Loss improved from 0.22559 to 0.22050\n",
      "[2024-01-09 06:41:03,044] Epoch: 19 | FT  | Train Loss: 0.21201 | Val Loss: 0.22050\n",
      "[2024-01-09 06:41:03,045] Epoch: 19 | Amp | Train Loss: 0.0189 | Val Loss: 0.0178\n",
      "[2024-01-09 06:41:03,046] Epoch: 19 | Ph  | Train Loss: 0.193 | Val Loss: 0.203\n",
      "[2024-01-09 06:41:03,046] Epoch: 19 | Ending LR: 0.000076 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:04<00:00,  1.14s/it]\n",
      "[2024-01-09 06:44:08,977] Saving improved model after Val Loss improved from 0.22050 to 0.21911\n",
      "[2024-01-09 06:44:09,079] Epoch: 20 | FT  | Train Loss: 0.20617 | Val Loss: 0.21911\n",
      "[2024-01-09 06:44:09,081] Epoch: 20 | Amp | Train Loss: 0.0185 | Val Loss: 0.0177\n",
      "[2024-01-09 06:44:09,082] Epoch: 20 | Ph  | Train Loss: 0.188 | Val Loss: 0.201\n",
      "[2024-01-09 06:44:09,083] Epoch: 20 | Ending LR: 0.000061 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:03<00:00,  1.14s/it]\n",
      "[2024-01-09 06:47:13,867] Saving improved model after Val Loss improved from 0.21911 to 0.21618\n",
      "[2024-01-09 06:47:13,975] Epoch: 21 | FT  | Train Loss: 0.20269 | Val Loss: 0.21618\n",
      "[2024-01-09 06:47:13,976] Epoch: 21 | Amp | Train Loss: 0.0182 | Val Loss: 0.0178\n",
      "[2024-01-09 06:47:13,977] Epoch: 21 | Ph  | Train Loss: 0.184 | Val Loss: 0.198\n",
      "[2024-01-09 06:47:13,979] Epoch: 21 | Ending LR: 0.000046 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:03<00:00,  1.14s/it]\n",
      "[2024-01-09 06:50:18,557] Epoch: 22 | FT  | Train Loss: 0.19835 | Val Loss: 0.21651\n",
      "[2024-01-09 06:50:18,558] Epoch: 22 | Amp | Train Loss: 0.0180 | Val Loss: 0.0176\n",
      "[2024-01-09 06:50:18,559] Epoch: 22 | Ph  | Train Loss: 0.180 | Val Loss: 0.199\n",
      "[2024-01-09 06:50:18,559] Epoch: 22 | Ending LR: 0.000031 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:06<00:00,  1.16s/it]\n",
      "[2024-01-09 06:53:26,393] Saving improved model after Val Loss improved from 0.21618 to 0.21124\n",
      "[2024-01-09 06:53:26,506] Epoch: 23 | FT  | Train Loss: 0.19529 | Val Loss: 0.21124\n",
      "[2024-01-09 06:53:26,507] Epoch: 23 | Amp | Train Loss: 0.0179 | Val Loss: 0.0176\n",
      "[2024-01-09 06:53:26,508] Epoch: 23 | Ph  | Train Loss: 0.177 | Val Loss: 0.194\n",
      "[2024-01-09 06:53:26,509] Epoch: 23 | Ending LR: 0.000022 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:04<00:00,  1.14s/it]\n",
      "[2024-01-09 06:56:32,415] Epoch: 24 | FT  | Train Loss: 0.19386 | Val Loss: 0.21371\n",
      "[2024-01-09 06:56:32,416] Epoch: 24 | Amp | Train Loss: 0.0179 | Val Loss: 0.0176\n",
      "[2024-01-09 06:56:32,417] Epoch: 24 | Ph  | Train Loss: 0.176 | Val Loss: 0.196\n",
      "[2024-01-09 06:56:32,418] Epoch: 24 | Ending LR: 0.000030 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:05<00:00,  1.15s/it]\n",
      "[2024-01-09 06:59:39,770] Epoch: 25 | FT  | Train Loss: 0.19426 | Val Loss: 0.21148\n",
      "[2024-01-09 06:59:39,771] Epoch: 25 | Amp | Train Loss: 0.0180 | Val Loss: 0.0176\n",
      "[2024-01-09 06:59:39,772] Epoch: 25 | Ph  | Train Loss: 0.176 | Val Loss: 0.194\n",
      "[2024-01-09 06:59:39,772] Epoch: 25 | Ending LR: 0.000037 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:05<00:00,  1.15s/it]\n",
      "[2024-01-09 07:02:46,673] Epoch: 26 | FT  | Train Loss: 0.19389 | Val Loss: 0.21206\n",
      "[2024-01-09 07:02:46,674] Epoch: 26 | Amp | Train Loss: 0.0179 | Val Loss: 0.0185\n",
      "[2024-01-09 07:02:46,674] Epoch: 26 | Ph  | Train Loss: 0.176 | Val Loss: 0.194\n",
      "[2024-01-09 07:02:46,675] Epoch: 26 | Ending LR: 0.000045 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:03<00:00,  1.14s/it]\n",
      "[2024-01-09 07:05:51,851] Epoch: 27 | FT  | Train Loss: 0.19373 | Val Loss: 0.21835\n",
      "[2024-01-09 07:05:51,852] Epoch: 27 | Amp | Train Loss: 0.0179 | Val Loss: 0.0175\n",
      "[2024-01-09 07:05:51,853] Epoch: 27 | Ph  | Train Loss: 0.176 | Val Loss: 0.201\n",
      "[2024-01-09 07:05:51,853] Epoch: 27 | Ending LR: 0.000053 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:06<00:00,  1.16s/it]\n",
      "[2024-01-09 07:08:59,964] Epoch: 28 | FT  | Train Loss: 0.19498 | Val Loss: 0.21376\n",
      "[2024-01-09 07:08:59,965] Epoch: 28 | Amp | Train Loss: 0.0182 | Val Loss: 0.0176\n",
      "[2024-01-09 07:08:59,965] Epoch: 28 | Ph  | Train Loss: 0.177 | Val Loss: 0.196\n",
      "[2024-01-09 07:08:59,966] Epoch: 28 | Ending LR: 0.000060 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:05<00:00,  1.15s/it]\n",
      "[2024-01-09 07:12:06,946] Saving improved model after Val Loss improved from 0.21124 to 0.21014\n",
      "[2024-01-09 07:12:07,051] Epoch: 29 | FT  | Train Loss: 0.19247 | Val Loss: 0.21014\n",
      "[2024-01-09 07:12:07,052] Epoch: 29 | Amp | Train Loss: 0.0179 | Val Loss: 0.0176\n",
      "[2024-01-09 07:12:07,052] Epoch: 29 | Ph  | Train Loss: 0.175 | Val Loss: 0.193\n",
      "[2024-01-09 07:12:07,053] Epoch: 29 | Ending LR: 0.000062 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:05<00:00,  1.15s/it]\n",
      "[2024-01-09 07:15:14,154] Epoch: 30 | FT  | Train Loss: 0.18946 | Val Loss: 0.21253\n",
      "[2024-01-09 07:15:14,154] Epoch: 30 | Amp | Train Loss: 0.0177 | Val Loss: 0.0176\n",
      "[2024-01-09 07:15:14,155] Epoch: 30 | Ph  | Train Loss: 0.172 | Val Loss: 0.195\n",
      "[2024-01-09 07:15:14,156] Epoch: 30 | Ending LR: 0.000055 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:03<00:00,  1.14s/it]\n",
      "[2024-01-09 07:18:19,151] Epoch: 31 | FT  | Train Loss: 0.18603 | Val Loss: 0.21029\n",
      "[2024-01-09 07:18:19,152] Epoch: 31 | Amp | Train Loss: 0.0176 | Val Loss: 0.0180\n",
      "[2024-01-09 07:18:19,153] Epoch: 31 | Ph  | Train Loss: 0.168 | Val Loss: 0.192\n",
      "[2024-01-09 07:18:19,153] Epoch: 31 | Ending LR: 0.000047 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:07<00:00,  1.16s/it]\n",
      "[2024-01-09 07:21:27,763] Saving improved model after Val Loss improved from 0.21014 to 0.20631\n",
      "[2024-01-09 07:21:27,866] Epoch: 32 | FT  | Train Loss: 0.18297 | Val Loss: 0.20631\n",
      "[2024-01-09 07:21:27,867] Epoch: 32 | Amp | Train Loss: 0.0176 | Val Loss: 0.0173\n",
      "[2024-01-09 07:21:27,868] Epoch: 32 | Ph  | Train Loss: 0.165 | Val Loss: 0.189\n",
      "[2024-01-09 07:21:27,869] Epoch: 32 | Ending LR: 0.000039 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:06<00:00,  1.16s/it]\n",
      "[2024-01-09 07:24:35,452] Saving improved model after Val Loss improved from 0.20631 to 0.20515\n",
      "[2024-01-09 07:24:35,548] Epoch: 33 | FT  | Train Loss: 0.18075 | Val Loss: 0.20515\n",
      "[2024-01-09 07:24:35,549] Epoch: 33 | Amp | Train Loss: 0.0174 | Val Loss: 0.0177\n",
      "[2024-01-09 07:24:35,550] Epoch: 33 | Ph  | Train Loss: 0.163 | Val Loss: 0.187\n",
      "[2024-01-09 07:24:35,551] Epoch: 33 | Ending LR: 0.000032 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:07<00:00,  1.17s/it]\n",
      "[2024-01-09 07:27:44,708] Saving improved model after Val Loss improved from 0.20515 to 0.20426\n",
      "[2024-01-09 07:27:44,811] Epoch: 34 | FT  | Train Loss: 0.17814 | Val Loss: 0.20426\n",
      "[2024-01-09 07:27:44,812] Epoch: 34 | Amp | Train Loss: 0.0173 | Val Loss: 0.0173\n",
      "[2024-01-09 07:27:44,812] Epoch: 34 | Ph  | Train Loss: 0.161 | Val Loss: 0.187\n",
      "[2024-01-09 07:27:44,813] Epoch: 34 | Ending LR: 0.000024 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:09<00:00,  1.17s/it]\n",
      "[2024-01-09 07:30:55,451] Saving improved model after Val Loss improved from 0.20426 to 0.20342\n",
      "[2024-01-09 07:30:55,562] Epoch: 35 | FT  | Train Loss: 0.17571 | Val Loss: 0.20342\n",
      "[2024-01-09 07:30:55,563] Epoch: 35 | Amp | Train Loss: 0.0171 | Val Loss: 0.0173\n",
      "[2024-01-09 07:30:55,564] Epoch: 35 | Ph  | Train Loss: 0.159 | Val Loss: 0.186\n",
      "[2024-01-09 07:30:55,565] Epoch: 35 | Ending LR: 0.000022 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:06<00:00,  1.16s/it]\n",
      "[2024-01-09 07:34:03,866] Epoch: 36 | FT  | Train Loss: 0.17575 | Val Loss: 0.20611\n",
      "[2024-01-09 07:34:03,867] Epoch: 36 | Amp | Train Loss: 0.0173 | Val Loss: 0.0176\n",
      "[2024-01-09 07:34:03,868] Epoch: 36 | Ph  | Train Loss: 0.158 | Val Loss: 0.188\n",
      "[2024-01-09 07:34:03,869] Epoch: 36 | Ending LR: 0.000025 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:05<00:00,  1.15s/it]\n",
      "[2024-01-09 07:37:11,029] Epoch: 37 | FT  | Train Loss: 0.17533 | Val Loss: 0.20483\n",
      "[2024-01-09 07:37:11,031] Epoch: 37 | Amp | Train Loss: 0.0172 | Val Loss: 0.0173\n",
      "[2024-01-09 07:37:11,032] Epoch: 37 | Ph  | Train Loss: 0.158 | Val Loss: 0.187\n",
      "[2024-01-09 07:37:11,032] Epoch: 37 | Ending LR: 0.000029 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:05<00:00,  1.15s/it]\n",
      "[2024-01-09 07:40:18,301] Saving improved model after Val Loss improved from 0.20342 to 0.20302\n",
      "[2024-01-09 07:40:18,386] Epoch: 38 | FT  | Train Loss: 0.17480 | Val Loss: 0.20302\n",
      "[2024-01-09 07:40:18,387] Epoch: 38 | Amp | Train Loss: 0.0171 | Val Loss: 0.0173\n",
      "[2024-01-09 07:40:18,388] Epoch: 38 | Ph  | Train Loss: 0.158 | Val Loss: 0.186\n",
      "[2024-01-09 07:40:18,389] Epoch: 38 | Ending LR: 0.000033 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:04<00:00,  1.14s/it]\n",
      "[2024-01-09 07:43:23,982] Epoch: 39 | FT  | Train Loss: 0.17469 | Val Loss: 0.20454\n",
      "[2024-01-09 07:43:23,983] Epoch: 39 | Amp | Train Loss: 0.0171 | Val Loss: 0.0173\n",
      "[2024-01-09 07:43:23,984] Epoch: 39 | Ph  | Train Loss: 0.158 | Val Loss: 0.187\n",
      "[2024-01-09 07:43:23,984] Epoch: 39 | Ending LR: 0.000037 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:06<00:00,  1.16s/it]\n",
      "[2024-01-09 07:46:32,426] Epoch: 40 | FT  | Train Loss: 0.17440 | Val Loss: 0.20477\n",
      "[2024-01-09 07:46:32,427] Epoch: 40 | Amp | Train Loss: 0.0172 | Val Loss: 0.0181\n",
      "[2024-01-09 07:46:32,427] Epoch: 40 | Ph  | Train Loss: 0.157 | Val Loss: 0.187\n",
      "[2024-01-09 07:46:32,428] Epoch: 40 | Ending LR: 0.000041 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:05<00:00,  1.15s/it]\n",
      "[2024-01-09 07:49:39,044] Epoch: 41 | FT  | Train Loss: 0.17363 | Val Loss: 0.20416\n",
      "[2024-01-09 07:49:39,046] Epoch: 41 | Amp | Train Loss: 0.0170 | Val Loss: 0.0180\n",
      "[2024-01-09 07:49:39,046] Epoch: 41 | Ph  | Train Loss: 0.157 | Val Loss: 0.186\n",
      "[2024-01-09 07:49:39,047] Epoch: 41 | Ending LR: 0.000041 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:06<00:00,  1.16s/it]\n",
      "[2024-01-09 07:52:47,375] Epoch: 42 | FT  | Train Loss: 0.17208 | Val Loss: 0.20357\n",
      "[2024-01-09 07:52:47,377] Epoch: 42 | Amp | Train Loss: 0.0169 | Val Loss: 0.0172\n",
      "[2024-01-09 07:52:47,378] Epoch: 42 | Ph  | Train Loss: 0.155 | Val Loss: 0.186\n",
      "[2024-01-09 07:52:47,378] Epoch: 42 | Ending LR: 0.000037 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:06<00:00,  1.16s/it]\n",
      "[2024-01-09 07:55:55,761] Saving improved model after Val Loss improved from 0.20302 to 0.20266\n",
      "[2024-01-09 07:55:55,865] Epoch: 43 | FT  | Train Loss: 0.17020 | Val Loss: 0.20266\n",
      "[2024-01-09 07:55:55,866] Epoch: 43 | Amp | Train Loss: 0.0168 | Val Loss: 0.0171\n",
      "[2024-01-09 07:55:55,866] Epoch: 43 | Ph  | Train Loss: 0.153 | Val Loss: 0.186\n",
      "[2024-01-09 07:55:55,867] Epoch: 43 | Ending LR: 0.000033 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:05<00:00,  1.15s/it]\n",
      "[2024-01-09 07:59:02,645] Saving improved model after Val Loss improved from 0.20266 to 0.20152\n",
      "[2024-01-09 07:59:02,749] Epoch: 44 | FT  | Train Loss: 0.16793 | Val Loss: 0.20152\n",
      "[2024-01-09 07:59:02,750] Epoch: 44 | Amp | Train Loss: 0.0167 | Val Loss: 0.0171\n",
      "[2024-01-09 07:59:02,750] Epoch: 44 | Ph  | Train Loss: 0.151 | Val Loss: 0.184\n",
      "[2024-01-09 07:59:02,751] Epoch: 44 | Ending LR: 0.000029 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:05<00:00,  1.15s/it]\n",
      "[2024-01-09 08:02:09,536] Epoch: 45 | FT  | Train Loss: 0.16630 | Val Loss: 0.20343\n",
      "[2024-01-09 08:02:09,537] Epoch: 45 | Amp | Train Loss: 0.0165 | Val Loss: 0.0172\n",
      "[2024-01-09 08:02:09,538] Epoch: 45 | Ph  | Train Loss: 0.150 | Val Loss: 0.186\n",
      "[2024-01-09 08:02:09,539] Epoch: 45 | Ending LR: 0.000025 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:05<00:00,  1.15s/it]\n",
      "[2024-01-09 08:05:16,979] Epoch: 46 | FT  | Train Loss: 0.16532 | Val Loss: 0.20484\n",
      "[2024-01-09 08:05:16,980] Epoch: 46 | Amp | Train Loss: 0.0164 | Val Loss: 0.0175\n",
      "[2024-01-09 08:05:16,981] Epoch: 46 | Ph  | Train Loss: 0.149 | Val Loss: 0.187\n",
      "[2024-01-09 08:05:16,982] Epoch: 46 | Ending LR: 0.000022 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:04<00:00,  1.15s/it]\n",
      "[2024-01-09 08:08:23,178] Saving improved model after Val Loss improved from 0.20152 to 0.20029\n",
      "[2024-01-09 08:08:23,277] Epoch: 47 | FT  | Train Loss: 0.16385 | Val Loss: 0.20029\n",
      "[2024-01-09 08:08:23,278] Epoch: 47 | Amp | Train Loss: 0.0164 | Val Loss: 0.0171\n",
      "[2024-01-09 08:08:23,278] Epoch: 47 | Ph  | Train Loss: 0.147 | Val Loss: 0.183\n",
      "[2024-01-09 08:08:23,279] Epoch: 47 | Ending LR: 0.000021 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:04<00:00,  1.15s/it]\n",
      "[2024-01-09 08:11:29,319] Epoch: 48 | FT  | Train Loss: 0.16330 | Val Loss: 0.20171\n",
      "[2024-01-09 08:11:29,321] Epoch: 48 | Amp | Train Loss: 0.0163 | Val Loss: 0.0181\n",
      "[2024-01-09 08:11:29,321] Epoch: 48 | Ph  | Train Loss: 0.147 | Val Loss: 0.184\n",
      "[2024-01-09 08:11:29,322] Epoch: 48 | Ending LR: 0.000023 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:05<00:00,  1.15s/it]\n",
      "[2024-01-09 08:14:36,931] Saving improved model after Val Loss improved from 0.20029 to 0.19997\n",
      "[2024-01-09 08:14:37,042] Epoch: 49 | FT  | Train Loss: 0.16276 | Val Loss: 0.19997\n",
      "[2024-01-09 08:14:37,043] Epoch: 49 | Amp | Train Loss: 0.0165 | Val Loss: 0.0170\n",
      "[2024-01-09 08:14:37,044] Epoch: 49 | Ph  | Train Loss: 0.146 | Val Loss: 0.183\n",
      "[2024-01-09 08:14:37,045] Epoch: 49 | Ending LR: 0.000025 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:06<00:00,  1.16s/it]\n",
      "[2024-01-09 08:17:45,127] Epoch: 50 | FT  | Train Loss: 0.16273 | Val Loss: 0.20055\n",
      "[2024-01-09 08:17:45,128] Epoch: 50 | Amp | Train Loss: 0.0163 | Val Loss: 0.0171\n",
      "[2024-01-09 08:17:45,128] Epoch: 50 | Ph  | Train Loss: 0.146 | Val Loss: 0.183\n",
      "[2024-01-09 08:17:45,129] Epoch: 50 | Ending LR: 0.000027 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:03<00:00,  1.14s/it]\n",
      "[2024-01-09 08:20:50,190] Epoch: 51 | FT  | Train Loss: 0.16282 | Val Loss: 0.20010\n",
      "[2024-01-09 08:20:50,191] Epoch: 51 | Amp | Train Loss: 0.0162 | Val Loss: 0.0177\n",
      "[2024-01-09 08:20:50,191] Epoch: 51 | Ph  | Train Loss: 0.147 | Val Loss: 0.182\n",
      "[2024-01-09 08:20:50,192] Epoch: 51 | Ending LR: 0.000029 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:06<00:00,  1.16s/it]\n",
      "[2024-01-09 08:23:58,274] Epoch: 52 | FT  | Train Loss: 0.16176 | Val Loss: 0.20032\n",
      "[2024-01-09 08:23:58,275] Epoch: 52 | Amp | Train Loss: 0.0162 | Val Loss: 0.0170\n",
      "[2024-01-09 08:23:58,276] Epoch: 52 | Ph  | Train Loss: 0.146 | Val Loss: 0.183\n",
      "[2024-01-09 08:23:58,276] Epoch: 52 | Ending LR: 0.000031 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:06<00:00,  1.16s/it]\n",
      "[2024-01-09 08:27:06,571] Epoch: 53 | FT  | Train Loss: 0.16111 | Val Loss: 0.20042\n",
      "[2024-01-09 08:27:06,572] Epoch: 53 | Amp | Train Loss: 0.0162 | Val Loss: 0.0170\n",
      "[2024-01-09 08:27:06,573] Epoch: 53 | Ph  | Train Loss: 0.145 | Val Loss: 0.183\n",
      "[2024-01-09 08:27:06,573] Epoch: 53 | Ending LR: 0.000030 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:04<00:00,  1.15s/it]\n",
      "[2024-01-09 08:30:12,818] Epoch: 54 | FT  | Train Loss: 0.15979 | Val Loss: 0.20131\n",
      "[2024-01-09 08:30:12,819] Epoch: 54 | Amp | Train Loss: 0.0161 | Val Loss: 0.0173\n",
      "[2024-01-09 08:30:12,819] Epoch: 54 | Ph  | Train Loss: 0.144 | Val Loss: 0.184\n",
      "[2024-01-09 08:30:12,820] Epoch: 54 | Ending LR: 0.000028 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:04<00:00,  1.14s/it]\n",
      "[2024-01-09 08:33:18,663] Saving improved model after Val Loss improved from 0.19997 to 0.19946\n",
      "[2024-01-09 08:33:18,768] Epoch: 55 | FT  | Train Loss: 0.15870 | Val Loss: 0.19946\n",
      "[2024-01-09 08:33:18,769] Epoch: 55 | Amp | Train Loss: 0.0159 | Val Loss: 0.0169\n",
      "[2024-01-09 08:33:18,770] Epoch: 55 | Ph  | Train Loss: 0.143 | Val Loss: 0.183\n",
      "[2024-01-09 08:33:18,770] Epoch: 55 | Ending LR: 0.000026 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:05<00:00,  1.15s/it]\n",
      "[2024-01-09 08:36:25,694] Epoch: 56 | FT  | Train Loss: 0.15765 | Val Loss: 0.20080\n",
      "[2024-01-09 08:36:25,695] Epoch: 56 | Amp | Train Loss: 0.0160 | Val Loss: 0.0170\n",
      "[2024-01-09 08:36:25,695] Epoch: 56 | Ph  | Train Loss: 0.142 | Val Loss: 0.184\n",
      "[2024-01-09 08:36:25,696] Epoch: 56 | Ending LR: 0.000024 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:06<00:00,  1.16s/it]\n",
      "[2024-01-09 08:39:33,485] Saving improved model after Val Loss improved from 0.19946 to 0.19865\n",
      "[2024-01-09 08:39:33,585] Epoch: 57 | FT  | Train Loss: 0.15644 | Val Loss: 0.19865\n",
      "[2024-01-09 08:39:33,585] Epoch: 57 | Amp | Train Loss: 0.0158 | Val Loss: 0.0169\n",
      "[2024-01-09 08:39:33,586] Epoch: 57 | Ph  | Train Loss: 0.141 | Val Loss: 0.182\n",
      "[2024-01-09 08:39:33,586] Epoch: 57 | Ending LR: 0.000022 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:08<00:00,  1.17s/it]\n",
      "[2024-01-09 08:42:43,689] Epoch: 58 | FT  | Train Loss: 0.15576 | Val Loss: 0.20186\n",
      "[2024-01-09 08:42:43,690] Epoch: 58 | Amp | Train Loss: 0.0157 | Val Loss: 0.0169\n",
      "[2024-01-09 08:42:43,691] Epoch: 58 | Ph  | Train Loss: 0.140 | Val Loss: 0.185\n",
      "[2024-01-09 08:42:43,692] Epoch: 58 | Ending LR: 0.000020 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:04<00:00,  1.15s/it]\n",
      "[2024-01-09 08:45:49,912] Epoch: 59 | FT  | Train Loss: 0.15438 | Val Loss: 0.19914\n",
      "[2024-01-09 08:45:49,913] Epoch: 59 | Amp | Train Loss: 0.0156 | Val Loss: 0.0168\n",
      "[2024-01-09 08:45:49,914] Epoch: 59 | Ph  | Train Loss: 0.139 | Val Loss: 0.182\n",
      "[2024-01-09 08:45:49,914] Epoch: 59 | Ending LR: 0.000021 \n",
      "[2024-01-09 08:45:50,018] Decimating dataset to 0.5 of the original size...\n",
      "[2024-01-09 08:45:50,149] Using DataParallel with 2 devices.\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 134/134 [02:34<00:00,  1.15s/it]\n",
      "[2024-01-09 08:48:25,780] Saving improved model after Val Loss improved from inf to 0.63991\n",
      "[2024-01-09 08:48:25,839] Epoch: 0 | FT  | Train Loss: 0.72539 | Val Loss: 0.63991\n",
      "[2024-01-09 08:48:25,839] Epoch: 0 | Amp | Train Loss: 0.1504 | Val Loss: 0.0788\n",
      "[2024-01-09 08:48:25,840] Epoch: 0 | Ph  | Train Loss: 0.575 | Val Loss: 0.561\n",
      "[2024-01-09 08:48:25,841] Epoch: 0 | Ending LR: 0.000050 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 134/134 [02:35<00:00,  1.16s/it]\n",
      "[2024-01-09 08:51:03,061] Saving improved model after Val Loss improved from 0.63991 to 0.58461\n",
      "[2024-01-09 08:51:03,164] Epoch: 1 | FT  | Train Loss: 0.61149 | Val Loss: 0.58461\n",
      "[2024-01-09 08:51:03,165] Epoch: 1 | Amp | Train Loss: 0.0443 | Val Loss: 0.0244\n",
      "[2024-01-09 08:51:03,166] Epoch: 1 | Ph  | Train Loss: 0.567 | Val Loss: 0.560\n",
      "[2024-01-09 08:51:03,167] Epoch: 1 | Ending LR: 0.000080 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 134/134 [02:36<00:00,  1.17s/it]\n",
      "[2024-01-09 08:53:40,702] Saving improved model after Val Loss improved from 0.58461 to 0.57925\n",
      "[2024-01-09 08:53:40,789] Epoch: 2 | FT  | Train Loss: 0.58253 | Val Loss: 0.57925\n",
      "[2024-01-09 08:53:40,790] Epoch: 2 | Amp | Train Loss: 0.0224 | Val Loss: 0.0308\n",
      "[2024-01-09 08:53:40,791] Epoch: 2 | Ph  | Train Loss: 0.560 | Val Loss: 0.548\n",
      "[2024-01-09 08:53:40,791] Epoch: 2 | Ending LR: 0.000111 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 134/134 [02:33<00:00,  1.15s/it]\n",
      "[2024-01-09 08:56:15,585] Saving improved model after Val Loss improved from 0.57925 to 0.46583\n",
      "[2024-01-09 08:56:15,691] Epoch: 3 | FT  | Train Loss: 0.54033 | Val Loss: 0.46583\n",
      "[2024-01-09 08:56:15,692] Epoch: 3 | Amp | Train Loss: 0.0232 | Val Loss: 0.0246\n",
      "[2024-01-09 08:56:15,692] Epoch: 3 | Ph  | Train Loss: 0.517 | Val Loss: 0.441\n",
      "[2024-01-09 08:56:15,693] Epoch: 3 | Ending LR: 0.000141 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 134/134 [02:36<00:00,  1.17s/it]\n",
      "[2024-01-09 08:58:53,600] Saving improved model after Val Loss improved from 0.46583 to 0.37244\n",
      "[2024-01-09 08:58:53,706] Epoch: 4 | FT  | Train Loss: 0.42150 | Val Loss: 0.37244\n",
      "[2024-01-09 08:58:53,707] Epoch: 4 | Amp | Train Loss: 0.0224 | Val Loss: 0.0245\n",
      "[2024-01-09 08:58:53,708] Epoch: 4 | Ph  | Train Loss: 0.399 | Val Loss: 0.348\n",
      "[2024-01-09 08:58:53,709] Epoch: 4 | Ending LR: 0.000171 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 134/134 [02:33<00:00,  1.15s/it]\n",
      "[2024-01-09 09:01:28,974] Saving improved model after Val Loss improved from 0.37244 to 0.32021\n",
      "[2024-01-09 09:01:29,081] Epoch: 5 | FT  | Train Loss: 0.35106 | Val Loss: 0.32021\n",
      "[2024-01-09 09:01:29,082] Epoch: 5 | Amp | Train Loss: 0.0219 | Val Loss: 0.0231\n",
      "[2024-01-09 09:01:29,082] Epoch: 5 | Ph  | Train Loss: 0.329 | Val Loss: 0.297\n",
      "[2024-01-09 09:01:29,084] Epoch: 5 | Ending LR: 0.000199 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 134/134 [02:33<00:00,  1.14s/it]\n",
      "[2024-01-09 09:04:03,763] Saving improved model after Val Loss improved from 0.32021 to 0.28467\n",
      "[2024-01-09 09:04:03,875] Epoch: 6 | FT  | Train Loss: 0.30566 | Val Loss: 0.28467\n",
      "[2024-01-09 09:04:03,876] Epoch: 6 | Amp | Train Loss: 0.0205 | Val Loss: 0.0238\n",
      "[2024-01-09 09:04:03,876] Epoch: 6 | Ph  | Train Loss: 0.285 | Val Loss: 0.261\n",
      "[2024-01-09 09:04:03,877] Epoch: 6 | Ending LR: 0.000168 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 134/134 [02:34<00:00,  1.15s/it]\n",
      "[2024-01-09 09:06:39,686] Saving improved model after Val Loss improved from 0.28467 to 0.26666\n",
      "[2024-01-09 09:06:39,791] Epoch: 7 | FT  | Train Loss: 0.27887 | Val Loss: 0.26666\n",
      "[2024-01-09 09:06:39,792] Epoch: 7 | Amp | Train Loss: 0.0203 | Val Loss: 0.0227\n",
      "[2024-01-09 09:06:39,793] Epoch: 7 | Ph  | Train Loss: 0.259 | Val Loss: 0.244\n",
      "[2024-01-09 09:06:39,794] Epoch: 7 | Ending LR: 0.000138 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 134/134 [02:33<00:00,  1.15s/it]\n",
      "[2024-01-09 09:09:14,971] Saving improved model after Val Loss improved from 0.26666 to 0.26095\n",
      "[2024-01-09 09:09:15,073] Epoch: 8 | FT  | Train Loss: 0.26258 | Val Loss: 0.26095\n",
      "[2024-01-09 09:09:15,075] Epoch: 8 | Amp | Train Loss: 0.0200 | Val Loss: 0.0269\n",
      "[2024-01-09 09:09:15,076] Epoch: 8 | Ph  | Train Loss: 0.243 | Val Loss: 0.234\n",
      "[2024-01-09 09:09:15,077] Epoch: 8 | Ending LR: 0.000108 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 134/134 [02:33<00:00,  1.15s/it]\n",
      "[2024-01-09 09:11:50,329] Saving improved model after Val Loss improved from 0.26095 to 0.24956\n",
      "[2024-01-09 09:11:50,435] Epoch: 9 | FT  | Train Loss: 0.25222 | Val Loss: 0.24956\n",
      "[2024-01-09 09:11:50,435] Epoch: 9 | Amp | Train Loss: 0.0199 | Val Loss: 0.0223\n",
      "[2024-01-09 09:11:50,436] Epoch: 9 | Ph  | Train Loss: 0.232 | Val Loss: 0.227\n",
      "[2024-01-09 09:11:50,436] Epoch: 9 | Ending LR: 0.000078 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 134/134 [02:35<00:00,  1.16s/it]\n",
      "[2024-01-09 09:14:27,206] Saving improved model after Val Loss improved from 0.24956 to 0.24465\n",
      "[2024-01-09 09:14:27,314] Epoch: 10 | FT  | Train Loss: 0.24290 | Val Loss: 0.24465\n",
      "[2024-01-09 09:14:27,315] Epoch: 10 | Amp | Train Loss: 0.0196 | Val Loss: 0.0248\n",
      "[2024-01-09 09:14:27,316] Epoch: 10 | Ph  | Train Loss: 0.223 | Val Loss: 0.220\n",
      "[2024-01-09 09:14:27,316] Epoch: 10 | Ending LR: 0.000048 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 134/134 [02:39<00:00,  1.19s/it]\n",
      "[2024-01-09 09:17:07,792] Saving improved model after Val Loss improved from 0.24465 to 0.23850\n",
      "[2024-01-09 09:17:07,902] Epoch: 11 | FT  | Train Loss: 0.23565 | Val Loss: 0.23850\n",
      "[2024-01-09 09:17:07,903] Epoch: 11 | Amp | Train Loss: 0.0193 | Val Loss: 0.0224\n",
      "[2024-01-09 09:17:07,903] Epoch: 11 | Ph  | Train Loss: 0.216 | Val Loss: 0.216\n",
      "[2024-01-09 09:17:07,904] Epoch: 11 | Ending LR: 0.000021 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 134/134 [02:39<00:00,  1.19s/it]\n",
      "[2024-01-09 09:19:48,496] Saving improved model after Val Loss improved from 0.23850 to 0.23835\n",
      "[2024-01-09 09:19:48,609] Epoch: 12 | FT  | Train Loss: 0.23327 | Val Loss: 0.23835\n",
      "[2024-01-09 09:19:48,610] Epoch: 12 | Amp | Train Loss: 0.0192 | Val Loss: 0.0227\n",
      "[2024-01-09 09:19:48,611] Epoch: 12 | Ph  | Train Loss: 0.214 | Val Loss: 0.216\n",
      "[2024-01-09 09:19:48,611] Epoch: 12 | Ending LR: 0.000036 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 134/134 [02:38<00:00,  1.18s/it]\n",
      "[2024-01-09 09:22:28,127] Saving improved model after Val Loss improved from 0.23835 to 0.23736\n",
      "[2024-01-09 09:22:28,232] Epoch: 13 | FT  | Train Loss: 0.23293 | Val Loss: 0.23736\n",
      "[2024-01-09 09:22:28,233] Epoch: 13 | Amp | Train Loss: 0.0193 | Val Loss: 0.0222\n",
      "[2024-01-09 09:22:28,234] Epoch: 13 | Ph  | Train Loss: 0.214 | Val Loss: 0.215\n",
      "[2024-01-09 09:22:28,234] Epoch: 13 | Ending LR: 0.000052 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 134/134 [02:36<00:00,  1.16s/it]\n",
      "[2024-01-09 09:25:05,589] Epoch: 14 | FT  | Train Loss: 0.23316 | Val Loss: 0.24047\n",
      "[2024-01-09 09:25:05,591] Epoch: 14 | Amp | Train Loss: 0.0193 | Val Loss: 0.0227\n",
      "[2024-01-09 09:25:05,591] Epoch: 14 | Ph  | Train Loss: 0.214 | Val Loss: 0.218\n",
      "[2024-01-09 09:25:05,592] Epoch: 14 | Ending LR: 0.000067 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 134/134 [02:35<00:00,  1.16s/it]\n",
      "[2024-01-09 09:27:42,358] Saving improved model after Val Loss improved from 0.23736 to 0.23681\n",
      "[2024-01-09 09:27:42,454] Epoch: 15 | FT  | Train Loss: 0.23020 | Val Loss: 0.23681\n",
      "[2024-01-09 09:27:42,455] Epoch: 15 | Amp | Train Loss: 0.0194 | Val Loss: 0.0226\n",
      "[2024-01-09 09:27:42,456] Epoch: 15 | Ph  | Train Loss: 0.211 | Val Loss: 0.214\n",
      "[2024-01-09 09:27:42,456] Epoch: 15 | Ending LR: 0.000082 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 134/134 [02:34<00:00,  1.16s/it]\n",
      "[2024-01-09 09:30:18,761] Saving improved model after Val Loss improved from 0.23681 to 0.23511\n",
      "[2024-01-09 09:30:18,864] Epoch: 16 | FT  | Train Loss: 0.22912 | Val Loss: 0.23511\n",
      "[2024-01-09 09:30:18,865] Epoch: 16 | Amp | Train Loss: 0.0196 | Val Loss: 0.0222\n",
      "[2024-01-09 09:30:18,867] Epoch: 16 | Ph  | Train Loss: 0.209 | Val Loss: 0.213\n",
      "[2024-01-09 09:30:18,868] Epoch: 16 | Ending LR: 0.000097 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 134/134 [02:34<00:00,  1.15s/it]\n",
      "[2024-01-09 09:32:54,717] Epoch: 17 | FT  | Train Loss: 0.22617 | Val Loss: 0.23674\n",
      "[2024-01-09 09:32:54,719] Epoch: 17 | Amp | Train Loss: 0.0193 | Val Loss: 0.0240\n",
      "[2024-01-09 09:32:54,720] Epoch: 17 | Ph  | Train Loss: 0.207 | Val Loss: 0.213\n",
      "[2024-01-09 09:32:54,721] Epoch: 17 | Ending LR: 0.000108 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 134/134 [02:40<00:00,  1.20s/it]\n",
      "[2024-01-09 09:35:36,471] Saving improved model after Val Loss improved from 0.23511 to 0.22961\n",
      "[2024-01-09 09:35:36,572] Epoch: 18 | FT  | Train Loss: 0.22493 | Val Loss: 0.22961\n",
      "[2024-01-09 09:35:36,573] Epoch: 18 | Amp | Train Loss: 0.0197 | Val Loss: 0.0243\n",
      "[2024-01-09 09:35:36,574] Epoch: 18 | Ph  | Train Loss: 0.205 | Val Loss: 0.205\n",
      "[2024-01-09 09:35:36,575] Epoch: 18 | Ending LR: 0.000093 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 134/134 [02:33<00:00,  1.15s/it]\n",
      "[2024-01-09 09:38:11,445] Saving improved model after Val Loss improved from 0.22961 to 0.22882\n",
      "[2024-01-09 09:38:11,544] Epoch: 19 | FT  | Train Loss: 0.21825 | Val Loss: 0.22882\n",
      "[2024-01-09 09:38:11,545] Epoch: 19 | Amp | Train Loss: 0.0194 | Val Loss: 0.0222\n",
      "[2024-01-09 09:38:11,546] Epoch: 19 | Ph  | Train Loss: 0.199 | Val Loss: 0.207\n",
      "[2024-01-09 09:38:11,546] Epoch: 19 | Ending LR: 0.000078 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 134/134 [02:35<00:00,  1.16s/it]\n",
      "[2024-01-09 09:40:47,890] Saving improved model after Val Loss improved from 0.22882 to 0.22410\n",
      "[2024-01-09 09:40:47,995] Epoch: 20 | FT  | Train Loss: 0.21329 | Val Loss: 0.22410\n",
      "[2024-01-09 09:40:47,996] Epoch: 20 | Amp | Train Loss: 0.0191 | Val Loss: 0.0219\n",
      "[2024-01-09 09:40:47,996] Epoch: 20 | Ph  | Train Loss: 0.194 | Val Loss: 0.202\n",
      "[2024-01-09 09:40:47,997] Epoch: 20 | Ending LR: 0.000063 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 134/134 [02:39<00:00,  1.19s/it]\n",
      "[2024-01-09 09:43:28,701] Saving improved model after Val Loss improved from 0.22410 to 0.22391\n",
      "[2024-01-09 09:43:28,806] Epoch: 21 | FT  | Train Loss: 0.20804 | Val Loss: 0.22391\n",
      "[2024-01-09 09:43:28,807] Epoch: 21 | Amp | Train Loss: 0.0189 | Val Loss: 0.0220\n",
      "[2024-01-09 09:43:28,809] Epoch: 21 | Ph  | Train Loss: 0.189 | Val Loss: 0.202\n",
      "[2024-01-09 09:43:28,810] Epoch: 21 | Ending LR: 0.000048 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 134/134 [02:39<00:00,  1.19s/it]\n",
      "[2024-01-09 09:46:09,268] Saving improved model after Val Loss improved from 0.22391 to 0.21914\n",
      "[2024-01-09 09:46:09,358] Epoch: 22 | FT  | Train Loss: 0.20502 | Val Loss: 0.21914\n",
      "[2024-01-09 09:46:09,359] Epoch: 22 | Amp | Train Loss: 0.0186 | Val Loss: 0.0223\n",
      "[2024-01-09 09:46:09,360] Epoch: 22 | Ph  | Train Loss: 0.186 | Val Loss: 0.197\n",
      "[2024-01-09 09:46:09,360] Epoch: 22 | Ending LR: 0.000032 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 134/134 [02:40<00:00,  1.20s/it]\n",
      "[2024-01-09 09:48:50,895] Saving improved model after Val Loss improved from 0.21914 to 0.21748\n",
      "[2024-01-09 09:48:50,999] Epoch: 23 | FT  | Train Loss: 0.20133 | Val Loss: 0.21748\n",
      "[2024-01-09 09:48:51,000] Epoch: 23 | Amp | Train Loss: 0.0185 | Val Loss: 0.0219\n",
      "[2024-01-09 09:48:51,001] Epoch: 23 | Ph  | Train Loss: 0.183 | Val Loss: 0.196\n",
      "[2024-01-09 09:48:51,001] Epoch: 23 | Ending LR: 0.000021 \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 134/134 [02:38<00:00,  1.18s/it]\n",
      "[2024-01-09 09:51:30,653] Epoch: 24 | FT  | Train Loss: 0.20007 | Val Loss: 0.21828\n",
      "[2024-01-09 09:51:30,654] Epoch: 24 | Amp | Train Loss: 0.0185 | Val Loss: 0.0219\n",
      "[2024-01-09 09:51:30,655] Epoch: 24 | Ph  | Train Loss: 0.182 | Val Loss: 0.196\n",
      "[2024-01-09 09:51:30,655] Epoch: 24 | Ending LR: 0.000029 \n",
      " 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                     | 94/134 [01:52<00:49,  1.23s/it]"
     ]
    }
   ],
   "source": [
    "decimate_ratio_list = [0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]\n",
    "\n",
    "for decimate_ratio in decimate_ratio_list:\n",
    "    config_dict = PtychoNNTrainingConfigDict()\n",
    "    \n",
    "    config_dict['dataset_decimation_ratio'] = decimate_ratio\n",
    "    \n",
    "    config_dict['batch_size_per_process'] = 64\n",
    "    config_dict['num_epochs'] = 60\n",
    "    config_dict['learning_rate_per_process'] = 1e-4\n",
    "    config_dict['optimizer'] = 'adam'\n",
    "    config_dict['model_save_dir'] = '../../trained_models/model_36SpiralDatasets_dataDecimation_{}'.format(decimate_ratio)\n",
    "    config_dict['validation_ratio'] = 0.01\n",
    "    # Attention to transform_func and transform_func_kwargs. They must match the training data. \n",
    "    dataset = HDF5Dataset('data/data_train.h5', verbose=False, transform_func=transform_func_512_128, transform_func_kwargs=transform_func_kwargs_512_128)\n",
    "    config_dict['dataset'] = dataset\n",
    "    config_dict['model'] = (PtychoNNModel, {'n_levels': 4})\n",
    "    config_dict['debug'] = False\n",
    "    \n",
    "    trainer = PtychoNNTrainer(config_dict)\n",
    "    trainer.build()\n",
    "    \n",
    "    trainer.run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cee9d34-d678-46a0-adcf-664720e39601",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.plot_training_history()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
